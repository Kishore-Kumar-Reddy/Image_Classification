{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "# Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=h5.File('C:/Users/ykkr1/Downloads/NN_Project/SVHN_single_grey1.h5','r')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training,testing and validation data\n",
    "X_train=data['X_train']\n",
    "X_test=data['X_test']\n",
    "X_val=data['X_val']\n",
    "y_train=data['y_train']\n",
    "y_test=data['y_test']\n",
    "y_val=data['y_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data X----shape : (42000, 32, 32) and data type:  float32\n",
      "Testing data X-----shape : (18000, 32, 32) and data type:  float32\n",
      "Validation data X--shape : (60000, 32, 32) and data type:  float32\n",
      "Training data y----shape : (42000,) and data type:  float32\n",
      "Testing data y-----shape : (18000,) and data type:  uint8\n",
      "Validation data y--shape : (60000,) and data type:  uint8\n"
     ]
    }
   ],
   "source": [
    "# Print the shape and data type of train,test and validation data\n",
    "print(\"Training data X----shape :\",X_train.shape,\"and data type: \",X_train.dtype)\n",
    "print(\"Testing data X-----shape :\",X_test.shape,\"and data type: \",X_test.dtype)\n",
    "print(\"Validation data X--shape :\",X_val.shape,\"and data type: \",X_val.dtype)\n",
    "print(\"Training data y----shape :\",y_train.shape,\"and data type: \",X_train.dtype)\n",
    "print(\"Testing data y-----shape :\",y_test.shape,\"and data type: \",y_test.dtype)\n",
    "print(\"Validation data y--shape :\",y_val.shape,\"and data type: \",y_val.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets visualize some numbers using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18afd45d848>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# To enable plotting graphs in Jupyter Notebook\n",
    "%matplotlib inline\n",
    "print(\"Label:{}\".format(y_train[1000]))\n",
    "plt.imshow(X_train[1000],cmap='winter_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18afe4ba648>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Label:{}\".format(y_train[2000]))\n",
    "plt.imshow(X_train[2000],cmap='winter_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels for each of the above image is: [2 6 7 4 4 0 3 0 7 3]\n"
     ]
    }
   ],
   "source": [
    "# Visualizing the first 10 images with their labels\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(0,10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.imshow(X_train[i],cmap='winter_r')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print(\"Labels for each of the above image is:\",y_train[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape features\n",
    "* reshape() method gives a new shape to an array without changing its data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data from 2D to 1D---->32x32 to 1024\n",
    "X_train=np.asarray(X_train).reshape(42000,1024)\n",
    "X_test=np.asarray(X_test).reshape(18000,1024)\n",
    "X_val=np.asarray(X_val).reshape(60000,1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize features\n",
    "* Normalize the features from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254.9745\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.max())\n",
    "print(X_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Normalizing the features:----\n",
      "0.9999\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"After Normalizing the features:----\")\n",
    "\n",
    "X_train=X_train/255.0\n",
    "X_test=X_test/255.0\n",
    "X_val=X_val/255.0\n",
    "\n",
    "print(X_train.max())\n",
    "print(X_train.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode the class vector\n",
    "* convert this class vectors to binary class matrix\n",
    "* convert X_train,X_test and X_val\n",
    "* number of classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "y_train=tensorflow.keras.utils.to_categorical(y_train,num_classes=10)\n",
    "y_test=tensorflow.keras.utils.to_categorical(y_test,num_classes=10)\n",
    "y_val=tensorflow.keras.utils.to_categorical(y_val,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After One-hot encoding:---\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"After One-hot encoding:---\")\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024) (18000, 1024) (60000, 1024) (42000, 10) (18000, 10) (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape,X_val.shape, y_train.shape, y_test.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import regularizers,optimizers\n",
    "\n",
    "# Initilize the Neural Network Classifier\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Layer\n",
    "# Adding Input Layer and activation function ReLu\n",
    "model.add(Dense(512,input_shape=(1024,),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden Layer\n",
    "# Adding hidden layer and activation function ReLu\n",
    "model.add(Dense(512,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Layer\n",
    "# Adding output layer which is of 10 nodes and activation function softmax,because we have multiclass classification\n",
    "model.add(Dense(10,activation='softmax',kernel_regularizer=regularizers.l2(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using sgd optimizer and Categorical crossentropy as loss function and accuracy as a metric to monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the NN Classifier\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 2.2931 - accuracy: 0.1318 - val_loss: 2.2777 - val_accuracy: 0.1681\n",
      "Epoch 2/10\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 2.2710 - accuracy: 0.1700 - val_loss: 2.2623 - val_accuracy: 0.1578\n",
      "Epoch 3/10\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 2.2522 - accuracy: 0.2120 - val_loss: 2.2400 - val_accuracy: 0.2300\n",
      "Epoch 4/10\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 2.2286 - accuracy: 0.2503 - val_loss: 2.2140 - val_accuracy: 0.2925\n",
      "Epoch 5/10\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 2.2007 - accuracy: 0.2945 - val_loss: 2.1813 - val_accuracy: 0.3397\n",
      "Epoch 6/10\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 2.1647 - accuracy: 0.3345 - val_loss: 2.1427 - val_accuracy: 0.3670\n",
      "Epoch 7/10\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 2.1213 - accuracy: 0.3701 - val_loss: 2.0951 - val_accuracy: 0.3821\n",
      "Epoch 8/10\n",
      "210/210 [==============================] - 2s 8ms/step - loss: 2.0675 - accuracy: 0.4053 - val_loss: 2.0359 - val_accuracy: 0.4267\n",
      "Epoch 9/10\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 2.0040 - accuracy: 0.4310 - val_loss: 1.9680 - val_accuracy: 0.4422\n",
      "Epoch 10/10\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.9328 - accuracy: 0.4627 - val_loss: 1.8974 - val_accuracy: 0.4596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18ab0232348>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the NN to the Training data\n",
    "model.fit(X_train,y_train,validation_data=(X_val,y_val),batch_size=200,epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using adam optimizer and Categorical crossentropy as loss function and accuracy as a metric to monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the NN Classifier\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 1.7234 - accuracy: 0.4348 - val_loss: 1.3520 - val_accuracy: 0.5732\n",
      "Epoch 2/10\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.2314 - accuracy: 0.6137 - val_loss: 1.1157 - val_accuracy: 0.6514\n",
      "Epoch 3/10\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0698 - accuracy: 0.6685 - val_loss: 1.0135 - val_accuracy: 0.6886\n",
      "Epoch 4/10\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9674 - accuracy: 0.7007 - val_loss: 0.9668 - val_accuracy: 0.6975\n",
      "Epoch 5/10\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.8998 - accuracy: 0.7243 - val_loss: 0.8261 - val_accuracy: 0.7530\n",
      "Epoch 6/10\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.8469 - accuracy: 0.7402 - val_loss: 0.7906 - val_accuracy: 0.7595\n",
      "Epoch 7/10\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.7986 - accuracy: 0.7560 - val_loss: 0.7811 - val_accuracy: 0.7637\n",
      "Epoch 8/10\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.7717 - accuracy: 0.7617 - val_loss: 0.8095 - val_accuracy: 0.7483\n",
      "Epoch 9/10\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.7424 - accuracy: 0.7729 - val_loss: 0.7638 - val_accuracy: 0.7649\n",
      "Epoch 10/10\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.7161 - accuracy: 0.7833 - val_loss: 0.7109 - val_accuracy: 0.7808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18aaeba5f48>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the NN to the Training data\n",
    "model.fit(X_train,y_train,validation_data=(X_val,y_val),batch_size=200,epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model on validation data is very low either using sgd or adam.Now,we will try to change the learning rate of both sgd and adam optimizers and will compare the accuracy.As,we are taking learning rate small means model will learn slowly.So,we  have to take more number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the learning rate and momentum in sgd\n",
    "sgd=optimizers.SGD(lr=0.0001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the NN Classifier\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.6255 - accuracy: 0.8124 - val_loss: 0.6319 - val_accuracy: 0.8127\n",
      "Epoch 2/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.6031 - accuracy: 0.8216 - val_loss: 0.6239 - val_accuracy: 0.8164\n",
      "Epoch 3/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5971 - accuracy: 0.8230 - val_loss: 0.6200 - val_accuracy: 0.8174\n",
      "Epoch 4/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5935 - accuracy: 0.8245 - val_loss: 0.6170 - val_accuracy: 0.8183\n",
      "Epoch 5/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5909 - accuracy: 0.8250 - val_loss: 0.6156 - val_accuracy: 0.8188\n",
      "Epoch 6/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5892 - accuracy: 0.8255 - val_loss: 0.6137 - val_accuracy: 0.8195\n",
      "Epoch 7/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5877 - accuracy: 0.8261 - val_loss: 0.6130 - val_accuracy: 0.8197\n",
      "Epoch 8/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5867 - accuracy: 0.8272 - val_loss: 0.6116 - val_accuracy: 0.8207\n",
      "Epoch 9/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5855 - accuracy: 0.8273 - val_loss: 0.6107 - val_accuracy: 0.8209\n",
      "Epoch 10/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5846 - accuracy: 0.8271 - val_loss: 0.6100 - val_accuracy: 0.8212\n",
      "Epoch 11/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5837 - accuracy: 0.8281 - val_loss: 0.6093 - val_accuracy: 0.8221\n",
      "Epoch 12/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5831 - accuracy: 0.8283 - val_loss: 0.6088 - val_accuracy: 0.8220\n",
      "Epoch 13/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5824 - accuracy: 0.8280 - val_loss: 0.6081 - val_accuracy: 0.8223\n",
      "Epoch 14/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5817 - accuracy: 0.8288 - val_loss: 0.6078 - val_accuracy: 0.8221\n",
      "Epoch 15/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5811 - accuracy: 0.8287 - val_loss: 0.6071 - val_accuracy: 0.8220\n",
      "Epoch 16/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5806 - accuracy: 0.8289 - val_loss: 0.6066 - val_accuracy: 0.8224\n",
      "Epoch 17/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5800 - accuracy: 0.8292 - val_loss: 0.6063 - val_accuracy: 0.8221\n",
      "Epoch 18/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5797 - accuracy: 0.8294 - val_loss: 0.6058 - val_accuracy: 0.8224\n",
      "Epoch 19/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5791 - accuracy: 0.8295 - val_loss: 0.6053 - val_accuracy: 0.8230\n",
      "Epoch 20/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5787 - accuracy: 0.8296 - val_loss: 0.6049 - val_accuracy: 0.8232\n",
      "Epoch 21/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.5783 - accuracy: 0.8299 - val_loss: 0.6046 - val_accuracy: 0.8231\n",
      "Epoch 22/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5779 - accuracy: 0.8299 - val_loss: 0.6042 - val_accuracy: 0.8233\n",
      "Epoch 23/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5774 - accuracy: 0.8300 - val_loss: 0.6041 - val_accuracy: 0.8234\n",
      "Epoch 24/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5772 - accuracy: 0.8302 - val_loss: 0.6036 - val_accuracy: 0.8234\n",
      "Epoch 25/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5768 - accuracy: 0.8299 - val_loss: 0.6032 - val_accuracy: 0.8236\n",
      "Epoch 26/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5763 - accuracy: 0.8305 - val_loss: 0.6028 - val_accuracy: 0.8237\n",
      "Epoch 27/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5759 - accuracy: 0.8302 - val_loss: 0.6030 - val_accuracy: 0.8235\n",
      "Epoch 28/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5756 - accuracy: 0.8309 - val_loss: 0.6024 - val_accuracy: 0.8241\n",
      "Epoch 29/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5754 - accuracy: 0.8299 - val_loss: 0.6020 - val_accuracy: 0.8238\n",
      "Epoch 30/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5749 - accuracy: 0.8306 - val_loss: 0.6016 - val_accuracy: 0.8238\n",
      "Epoch 31/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5747 - accuracy: 0.8310 - val_loss: 0.6015 - val_accuracy: 0.8245\n",
      "Epoch 32/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5742 - accuracy: 0.8307 - val_loss: 0.6011 - val_accuracy: 0.8242\n",
      "Epoch 33/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5739 - accuracy: 0.8313 - val_loss: 0.6010 - val_accuracy: 0.8240\n",
      "Epoch 34/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5736 - accuracy: 0.8311 - val_loss: 0.6006 - val_accuracy: 0.8244\n",
      "Epoch 35/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5733 - accuracy: 0.8314 - val_loss: 0.6003 - val_accuracy: 0.8243\n",
      "Epoch 36/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5730 - accuracy: 0.8316 - val_loss: 0.6002 - val_accuracy: 0.8244\n",
      "Epoch 37/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5726 - accuracy: 0.8310 - val_loss: 0.5998 - val_accuracy: 0.8249\n",
      "Epoch 38/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5723 - accuracy: 0.8320 - val_loss: 0.5996 - val_accuracy: 0.8245\n",
      "Epoch 39/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5720 - accuracy: 0.8316 - val_loss: 0.5992 - val_accuracy: 0.8248\n",
      "Epoch 40/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5716 - accuracy: 0.8319 - val_loss: 0.5990 - val_accuracy: 0.8249\n",
      "Epoch 41/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5715 - accuracy: 0.8313 - val_loss: 0.5986 - val_accuracy: 0.8251\n",
      "Epoch 42/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5711 - accuracy: 0.8321 - val_loss: 0.5985 - val_accuracy: 0.8249\n",
      "Epoch 43/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5709 - accuracy: 0.8315 - val_loss: 0.5983 - val_accuracy: 0.8250\n",
      "Epoch 44/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5705 - accuracy: 0.8323 - val_loss: 0.5979 - val_accuracy: 0.8257\n",
      "Epoch 45/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5703 - accuracy: 0.8319 - val_loss: 0.5976 - val_accuracy: 0.8252\n",
      "Epoch 46/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5700 - accuracy: 0.8322 - val_loss: 0.5973 - val_accuracy: 0.8256\n",
      "Epoch 47/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5697 - accuracy: 0.8325 - val_loss: 0.5973 - val_accuracy: 0.8253\n",
      "Epoch 48/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5694 - accuracy: 0.8322 - val_loss: 0.5970 - val_accuracy: 0.8254\n",
      "Epoch 49/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5692 - accuracy: 0.8321 - val_loss: 0.5967 - val_accuracy: 0.8255\n",
      "Epoch 50/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5688 - accuracy: 0.8327 - val_loss: 0.5965 - val_accuracy: 0.8256\n",
      "Epoch 51/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5686 - accuracy: 0.8324 - val_loss: 0.5961 - val_accuracy: 0.8259\n",
      "Epoch 52/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5684 - accuracy: 0.8331 - val_loss: 0.5959 - val_accuracy: 0.8257\n",
      "Epoch 53/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5681 - accuracy: 0.8327 - val_loss: 0.5957 - val_accuracy: 0.8256\n",
      "Epoch 54/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5678 - accuracy: 0.8323 - val_loss: 0.5957 - val_accuracy: 0.8260\n",
      "Epoch 55/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5676 - accuracy: 0.8331 - val_loss: 0.5952 - val_accuracy: 0.8261\n",
      "Epoch 56/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5673 - accuracy: 0.8331 - val_loss: 0.5951 - val_accuracy: 0.8261\n",
      "Epoch 57/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5670 - accuracy: 0.8331 - val_loss: 0.5947 - val_accuracy: 0.8263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5668 - accuracy: 0.8334 - val_loss: 0.5946 - val_accuracy: 0.8260\n",
      "Epoch 59/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5666 - accuracy: 0.8329 - val_loss: 0.5948 - val_accuracy: 0.8264\n",
      "Epoch 60/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5662 - accuracy: 0.8332 - val_loss: 0.5941 - val_accuracy: 0.8265\n",
      "Epoch 61/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5660 - accuracy: 0.8331 - val_loss: 0.5940 - val_accuracy: 0.8265\n",
      "Epoch 62/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5658 - accuracy: 0.8335 - val_loss: 0.5937 - val_accuracy: 0.8261\n",
      "Epoch 63/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5655 - accuracy: 0.8339 - val_loss: 0.5935 - val_accuracy: 0.8268\n",
      "Epoch 64/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5653 - accuracy: 0.8340 - val_loss: 0.5933 - val_accuracy: 0.8267\n",
      "Epoch 65/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5650 - accuracy: 0.8336 - val_loss: 0.5931 - val_accuracy: 0.8260\n",
      "Epoch 66/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5647 - accuracy: 0.8341 - val_loss: 0.5930 - val_accuracy: 0.8268\n",
      "Epoch 67/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5646 - accuracy: 0.8342 - val_loss: 0.5927 - val_accuracy: 0.8263\n",
      "Epoch 68/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5642 - accuracy: 0.8340 - val_loss: 0.5925 - val_accuracy: 0.8264\n",
      "Epoch 69/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5641 - accuracy: 0.8337 - val_loss: 0.5921 - val_accuracy: 0.8267\n",
      "Epoch 70/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5638 - accuracy: 0.8340 - val_loss: 0.5920 - val_accuracy: 0.8268\n",
      "Epoch 71/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.5635 - accuracy: 0.8340 - val_loss: 0.5917 - val_accuracy: 0.8266\n",
      "Epoch 72/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.5633 - accuracy: 0.8338 - val_loss: 0.5915 - val_accuracy: 0.8270\n",
      "Epoch 73/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5630 - accuracy: 0.8341 - val_loss: 0.5913 - val_accuracy: 0.8270\n",
      "Epoch 74/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5627 - accuracy: 0.8343 - val_loss: 0.5912 - val_accuracy: 0.8263\n",
      "Epoch 75/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5626 - accuracy: 0.8340 - val_loss: 0.5908 - val_accuracy: 0.8272\n",
      "Epoch 76/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5624 - accuracy: 0.8341 - val_loss: 0.5907 - val_accuracy: 0.8275\n",
      "Epoch 77/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5621 - accuracy: 0.8345 - val_loss: 0.5904 - val_accuracy: 0.8273\n",
      "Epoch 78/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5617 - accuracy: 0.8343 - val_loss: 0.5909 - val_accuracy: 0.8278\n",
      "Epoch 79/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5616 - accuracy: 0.8344 - val_loss: 0.5902 - val_accuracy: 0.8272\n",
      "Epoch 80/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5611 - accuracy: 0.8343 - val_loss: 0.5898 - val_accuracy: 0.8281\n",
      "Epoch 81/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5610 - accuracy: 0.8350 - val_loss: 0.5897 - val_accuracy: 0.8273\n",
      "Epoch 82/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5608 - accuracy: 0.8346 - val_loss: 0.5893 - val_accuracy: 0.8275\n",
      "Epoch 83/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5603 - accuracy: 0.8348 - val_loss: 0.5890 - val_accuracy: 0.8279\n",
      "Epoch 84/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5602 - accuracy: 0.8352 - val_loss: 0.5891 - val_accuracy: 0.8275\n",
      "Epoch 85/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5600 - accuracy: 0.8350 - val_loss: 0.5887 - val_accuracy: 0.8278\n",
      "Epoch 86/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5597 - accuracy: 0.8354 - val_loss: 0.5885 - val_accuracy: 0.8277\n",
      "Epoch 87/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5595 - accuracy: 0.8351 - val_loss: 0.5884 - val_accuracy: 0.8286\n",
      "Epoch 88/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5594 - accuracy: 0.8354 - val_loss: 0.5881 - val_accuracy: 0.8281\n",
      "Epoch 89/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5591 - accuracy: 0.8354 - val_loss: 0.5879 - val_accuracy: 0.8281\n",
      "Epoch 90/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5588 - accuracy: 0.8355 - val_loss: 0.5879 - val_accuracy: 0.8281\n",
      "Epoch 91/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5587 - accuracy: 0.8351 - val_loss: 0.5877 - val_accuracy: 0.8278\n",
      "Epoch 92/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5584 - accuracy: 0.8352 - val_loss: 0.5874 - val_accuracy: 0.8284\n",
      "Epoch 93/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5583 - accuracy: 0.8354 - val_loss: 0.5872 - val_accuracy: 0.8280\n",
      "Epoch 94/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5580 - accuracy: 0.8355 - val_loss: 0.5870 - val_accuracy: 0.8285\n",
      "Epoch 95/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5577 - accuracy: 0.8358 - val_loss: 0.5868 - val_accuracy: 0.8286\n",
      "Epoch 96/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5575 - accuracy: 0.8357 - val_loss: 0.5867 - val_accuracy: 0.8287\n",
      "Epoch 97/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5573 - accuracy: 0.8363 - val_loss: 0.5866 - val_accuracy: 0.8284\n",
      "Epoch 98/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5572 - accuracy: 0.8360 - val_loss: 0.5864 - val_accuracy: 0.8285\n",
      "Epoch 99/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5570 - accuracy: 0.8360 - val_loss: 0.5861 - val_accuracy: 0.8287\n",
      "Epoch 100/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5567 - accuracy: 0.8356 - val_loss: 0.5861 - val_accuracy: 0.8283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18afc95e848>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the NN to the Training data\n",
    "model.fit(X_train,y_train,validation_data=(X_val,y_val),batch_size=200,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model on validation data using sgd with learning rate=0.0001 has shown significant improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the learning rate in adam\n",
    "adam=optimizers.Adam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the NN Classifier\n",
    "model.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5717 - accuracy: 0.8301 - val_loss: 0.5925 - val_accuracy: 0.8252\n",
      "Epoch 2/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5649 - accuracy: 0.8337 - val_loss: 0.5837 - val_accuracy: 0.8289\n",
      "Epoch 3/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5602 - accuracy: 0.8341 - val_loss: 0.5821 - val_accuracy: 0.8291\n",
      "Epoch 4/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5546 - accuracy: 0.8360 - val_loss: 0.5788 - val_accuracy: 0.8312\n",
      "Epoch 5/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5504 - accuracy: 0.8382 - val_loss: 0.5768 - val_accuracy: 0.8327\n",
      "Epoch 6/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5468 - accuracy: 0.8378 - val_loss: 0.5741 - val_accuracy: 0.8323\n",
      "Epoch 7/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5429 - accuracy: 0.8391 - val_loss: 0.5675 - val_accuracy: 0.8330\n",
      "Epoch 8/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5363 - accuracy: 0.8416 - val_loss: 0.5611 - val_accuracy: 0.8365\n",
      "Epoch 9/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5342 - accuracy: 0.8421 - val_loss: 0.5656 - val_accuracy: 0.8346\n",
      "Epoch 10/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5300 - accuracy: 0.8434 - val_loss: 0.5536 - val_accuracy: 0.8385\n",
      "Epoch 11/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5251 - accuracy: 0.8456 - val_loss: 0.5488 - val_accuracy: 0.8393\n",
      "Epoch 12/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5208 - accuracy: 0.8457 - val_loss: 0.5540 - val_accuracy: 0.8383\n",
      "Epoch 13/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5169 - accuracy: 0.8487 - val_loss: 0.5431 - val_accuracy: 0.8425\n",
      "Epoch 14/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5138 - accuracy: 0.8490 - val_loss: 0.5418 - val_accuracy: 0.8421\n",
      "Epoch 15/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5083 - accuracy: 0.8521 - val_loss: 0.5438 - val_accuracy: 0.8394\n",
      "Epoch 16/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5074 - accuracy: 0.8514 - val_loss: 0.5373 - val_accuracy: 0.8433\n",
      "Epoch 17/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5030 - accuracy: 0.8525 - val_loss: 0.5348 - val_accuracy: 0.8454\n",
      "Epoch 18/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4989 - accuracy: 0.8548 - val_loss: 0.5322 - val_accuracy: 0.8436\n",
      "Epoch 19/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4942 - accuracy: 0.8550 - val_loss: 0.5324 - val_accuracy: 0.8443\n",
      "Epoch 20/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4912 - accuracy: 0.8585 - val_loss: 0.5184 - val_accuracy: 0.8507\n",
      "Epoch 21/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4876 - accuracy: 0.8578 - val_loss: 0.5309 - val_accuracy: 0.8449\n",
      "Epoch 22/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4848 - accuracy: 0.8597 - val_loss: 0.5121 - val_accuracy: 0.8523\n",
      "Epoch 23/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4805 - accuracy: 0.8598 - val_loss: 0.5135 - val_accuracy: 0.8523\n",
      "Epoch 24/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4786 - accuracy: 0.8605 - val_loss: 0.5087 - val_accuracy: 0.8530\n",
      "Epoch 25/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4724 - accuracy: 0.8621 - val_loss: 0.5098 - val_accuracy: 0.8527\n",
      "Epoch 26/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4719 - accuracy: 0.8608 - val_loss: 0.5118 - val_accuracy: 0.8516\n",
      "Epoch 27/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4688 - accuracy: 0.8624 - val_loss: 0.5090 - val_accuracy: 0.8521\n",
      "Epoch 28/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4641 - accuracy: 0.8646 - val_loss: 0.4974 - val_accuracy: 0.8565\n",
      "Epoch 29/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4638 - accuracy: 0.8643 - val_loss: 0.4934 - val_accuracy: 0.8574\n",
      "Epoch 30/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4579 - accuracy: 0.8675 - val_loss: 0.4949 - val_accuracy: 0.8578\n",
      "Epoch 31/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4562 - accuracy: 0.8667 - val_loss: 0.4880 - val_accuracy: 0.8597\n",
      "Epoch 32/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4526 - accuracy: 0.8690 - val_loss: 0.4878 - val_accuracy: 0.8601\n",
      "Epoch 33/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4498 - accuracy: 0.8700 - val_loss: 0.4918 - val_accuracy: 0.8590\n",
      "Epoch 34/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4471 - accuracy: 0.8713 - val_loss: 0.4853 - val_accuracy: 0.8595\n",
      "Epoch 35/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4434 - accuracy: 0.8708 - val_loss: 0.4905 - val_accuracy: 0.8585\n",
      "Epoch 36/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4400 - accuracy: 0.8729 - val_loss: 0.4757 - val_accuracy: 0.8637\n",
      "Epoch 37/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4374 - accuracy: 0.8731 - val_loss: 0.4767 - val_accuracy: 0.8620\n",
      "Epoch 38/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4353 - accuracy: 0.8738 - val_loss: 0.4796 - val_accuracy: 0.8615\n",
      "Epoch 39/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4320 - accuracy: 0.8742 - val_loss: 0.4757 - val_accuracy: 0.8622\n",
      "Epoch 40/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4304 - accuracy: 0.8752 - val_loss: 0.4683 - val_accuracy: 0.8658\n",
      "Epoch 41/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4277 - accuracy: 0.8754 - val_loss: 0.4660 - val_accuracy: 0.8669\n",
      "Epoch 42/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4248 - accuracy: 0.8762 - val_loss: 0.4624 - val_accuracy: 0.8673\n",
      "Epoch 43/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4217 - accuracy: 0.8768 - val_loss: 0.4616 - val_accuracy: 0.8665\n",
      "Epoch 44/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4173 - accuracy: 0.8780 - val_loss: 0.4613 - val_accuracy: 0.8673\n",
      "Epoch 45/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4146 - accuracy: 0.8791 - val_loss: 0.4633 - val_accuracy: 0.8670\n",
      "Epoch 46/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4138 - accuracy: 0.8787 - val_loss: 0.4542 - val_accuracy: 0.8697\n",
      "Epoch 47/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4098 - accuracy: 0.8811 - val_loss: 0.4578 - val_accuracy: 0.8691\n",
      "Epoch 48/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4076 - accuracy: 0.8812 - val_loss: 0.4568 - val_accuracy: 0.8701\n",
      "Epoch 49/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4067 - accuracy: 0.8805 - val_loss: 0.4499 - val_accuracy: 0.8699\n",
      "Epoch 50/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4029 - accuracy: 0.8822 - val_loss: 0.4491 - val_accuracy: 0.8716\n",
      "Epoch 51/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4012 - accuracy: 0.8844 - val_loss: 0.4452 - val_accuracy: 0.8716\n",
      "Epoch 52/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3981 - accuracy: 0.8837 - val_loss: 0.4443 - val_accuracy: 0.8727\n",
      "Epoch 53/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3961 - accuracy: 0.8845 - val_loss: 0.4397 - val_accuracy: 0.8749\n",
      "Epoch 54/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3928 - accuracy: 0.8855 - val_loss: 0.4378 - val_accuracy: 0.8745\n",
      "Epoch 55/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3905 - accuracy: 0.8875 - val_loss: 0.4386 - val_accuracy: 0.8750\n",
      "Epoch 56/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3872 - accuracy: 0.8872 - val_loss: 0.4301 - val_accuracy: 0.8778\n",
      "Epoch 57/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3874 - accuracy: 0.8884 - val_loss: 0.4420 - val_accuracy: 0.8718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3825 - accuracy: 0.8888 - val_loss: 0.4335 - val_accuracy: 0.8757\n",
      "Epoch 59/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3805 - accuracy: 0.8890 - val_loss: 0.4306 - val_accuracy: 0.8767\n",
      "Epoch 60/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3782 - accuracy: 0.8900 - val_loss: 0.4303 - val_accuracy: 0.8769\n",
      "Epoch 61/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3760 - accuracy: 0.8898 - val_loss: 0.4231 - val_accuracy: 0.8799\n",
      "Epoch 62/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3736 - accuracy: 0.8910 - val_loss: 0.4254 - val_accuracy: 0.8793\n",
      "Epoch 63/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3711 - accuracy: 0.8918 - val_loss: 0.4215 - val_accuracy: 0.8791\n",
      "Epoch 64/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3703 - accuracy: 0.8925 - val_loss: 0.4207 - val_accuracy: 0.8797\n",
      "Epoch 65/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3687 - accuracy: 0.8930 - val_loss: 0.4210 - val_accuracy: 0.8800\n",
      "Epoch 66/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3647 - accuracy: 0.8931 - val_loss: 0.4208 - val_accuracy: 0.8795\n",
      "Epoch 67/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3627 - accuracy: 0.8947 - val_loss: 0.4127 - val_accuracy: 0.8834\n",
      "Epoch 68/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3604 - accuracy: 0.8954 - val_loss: 0.4115 - val_accuracy: 0.8837\n",
      "Epoch 69/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3574 - accuracy: 0.8971 - val_loss: 0.4297 - val_accuracy: 0.8749\n",
      "Epoch 70/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3571 - accuracy: 0.8967 - val_loss: 0.4148 - val_accuracy: 0.8814\n",
      "Epoch 71/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3557 - accuracy: 0.8955 - val_loss: 0.4151 - val_accuracy: 0.8819\n",
      "Epoch 72/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3504 - accuracy: 0.8982 - val_loss: 0.4105 - val_accuracy: 0.8827\n",
      "Epoch 73/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3501 - accuracy: 0.8988 - val_loss: 0.4080 - val_accuracy: 0.8845\n",
      "Epoch 74/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3483 - accuracy: 0.8989 - val_loss: 0.4008 - val_accuracy: 0.8867\n",
      "Epoch 75/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3453 - accuracy: 0.8996 - val_loss: 0.4111 - val_accuracy: 0.8824\n",
      "Epoch 76/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3437 - accuracy: 0.9009 - val_loss: 0.4060 - val_accuracy: 0.8854\n",
      "Epoch 77/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.3424 - accuracy: 0.9008 - val_loss: 0.3966 - val_accuracy: 0.8881\n",
      "Epoch 78/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3380 - accuracy: 0.9023 - val_loss: 0.3946 - val_accuracy: 0.8888\n",
      "Epoch 79/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3393 - accuracy: 0.9006 - val_loss: 0.4043 - val_accuracy: 0.8844\n",
      "Epoch 80/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3357 - accuracy: 0.9031 - val_loss: 0.4054 - val_accuracy: 0.8835\n",
      "Epoch 81/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3341 - accuracy: 0.9033 - val_loss: 0.3957 - val_accuracy: 0.8878\n",
      "Epoch 82/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3318 - accuracy: 0.9047 - val_loss: 0.3952 - val_accuracy: 0.8877\n",
      "Epoch 83/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3308 - accuracy: 0.9040 - val_loss: 0.3925 - val_accuracy: 0.8884\n",
      "Epoch 84/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3277 - accuracy: 0.9058 - val_loss: 0.3942 - val_accuracy: 0.8880\n",
      "Epoch 85/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.3253 - accuracy: 0.9059 - val_loss: 0.3911 - val_accuracy: 0.8886\n",
      "Epoch 86/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.3215 - accuracy: 0.9067 - val_loss: 0.3879 - val_accuracy: 0.8906\n",
      "Epoch 87/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3219 - accuracy: 0.9071 - val_loss: 0.3849 - val_accuracy: 0.8913\n",
      "Epoch 88/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3201 - accuracy: 0.9077 - val_loss: 0.3859 - val_accuracy: 0.8909\n",
      "Epoch 89/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3172 - accuracy: 0.9085 - val_loss: 0.3848 - val_accuracy: 0.8910\n",
      "Epoch 90/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.3170 - accuracy: 0.9090 - val_loss: 0.3909 - val_accuracy: 0.8890\n",
      "Epoch 91/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3132 - accuracy: 0.9097 - val_loss: 0.3885 - val_accuracy: 0.8892\n",
      "Epoch 92/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3135 - accuracy: 0.9096 - val_loss: 0.3796 - val_accuracy: 0.8939\n",
      "Epoch 93/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3111 - accuracy: 0.9095 - val_loss: 0.3862 - val_accuracy: 0.8917\n",
      "Epoch 94/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3102 - accuracy: 0.9110 - val_loss: 0.3749 - val_accuracy: 0.8958\n",
      "Epoch 95/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3097 - accuracy: 0.9107 - val_loss: 0.3844 - val_accuracy: 0.8912\n",
      "Epoch 96/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3058 - accuracy: 0.9136 - val_loss: 0.3763 - val_accuracy: 0.8950\n",
      "Epoch 97/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3040 - accuracy: 0.9126 - val_loss: 0.3790 - val_accuracy: 0.8929\n",
      "Epoch 98/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3010 - accuracy: 0.9143 - val_loss: 0.3701 - val_accuracy: 0.8968\n",
      "Epoch 99/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.2993 - accuracy: 0.9141 - val_loss: 0.3691 - val_accuracy: 0.8982\n",
      "Epoch 100/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.2970 - accuracy: 0.9145 - val_loss: 0.3671 - val_accuracy: 0.8970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18aaeb572c8>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the NN to the Training data\n",
    "model.fit(X_train,y_train,validation_data=(X_val,y_val),batch_size=200,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model on validation data using adam with learning rate=0.0001 has shown significant improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the Batch Normalization for training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "# Initilize the Neural Network Classifier\n",
    "model1=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Layer\n",
    "# Adding Input Layer and activation function ReLu\n",
    "model1.add(Dense(512,input_shape=(1024,),activation='relu'))\n",
    "\n",
    "#Adding BatchNormalization Layer\n",
    "model1.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden Layer\n",
    "# Adding hidden layer and activation function ReLu\n",
    "model1.add(Dense(512,activation='relu'))\n",
    "\n",
    "#Adding BatchNormalization Layer\n",
    "model1.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Layer\n",
    "# Adding output layer which is of 10 nodes and activation function softmax,because we have multiclass classification\n",
    "model1.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 796,682\n",
      "Trainable params: 794,634\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SGD optimizer with learning rate=0.0001 and momentum=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 2.5048 - accuracy: 0.1626 - val_loss: 2.2777 - val_accuracy: 0.1550\n",
      "Epoch 2/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 2.0990 - accuracy: 0.2865 - val_loss: 2.0489 - val_accuracy: 0.2860\n",
      "Epoch 3/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.8858 - accuracy: 0.3712 - val_loss: 1.8117 - val_accuracy: 0.4047\n",
      "Epoch 4/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.7329 - accuracy: 0.4362 - val_loss: 1.6693 - val_accuracy: 0.4675\n",
      "Epoch 5/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.6151 - accuracy: 0.4863 - val_loss: 1.5591 - val_accuracy: 0.5103\n",
      "Epoch 6/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.5188 - accuracy: 0.5262 - val_loss: 1.4746 - val_accuracy: 0.5466\n",
      "Epoch 7/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.4406 - accuracy: 0.5547 - val_loss: 1.4007 - val_accuracy: 0.5747\n",
      "Epoch 8/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.3723 - accuracy: 0.5849 - val_loss: 1.3398 - val_accuracy: 0.5967\n",
      "Epoch 9/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.3163 - accuracy: 0.6031 - val_loss: 1.2888 - val_accuracy: 0.6140\n",
      "Epoch 10/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.2673 - accuracy: 0.6200 - val_loss: 1.2428 - val_accuracy: 0.6314\n",
      "Epoch 11/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.2225 - accuracy: 0.6363 - val_loss: 1.1975 - val_accuracy: 0.6480\n",
      "Epoch 12/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1869 - accuracy: 0.6496 - val_loss: 1.1652 - val_accuracy: 0.6595\n",
      "Epoch 13/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1505 - accuracy: 0.6625 - val_loss: 1.1309 - val_accuracy: 0.6695\n",
      "Epoch 14/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.1191 - accuracy: 0.6701 - val_loss: 1.1022 - val_accuracy: 0.6798\n",
      "Epoch 15/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0905 - accuracy: 0.6802 - val_loss: 1.0763 - val_accuracy: 0.6873\n",
      "Epoch 16/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0660 - accuracy: 0.6876 - val_loss: 1.0549 - val_accuracy: 0.6931\n",
      "Epoch 17/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0443 - accuracy: 0.6941 - val_loss: 1.0267 - val_accuracy: 0.7005\n",
      "Epoch 18/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0213 - accuracy: 0.7015 - val_loss: 1.0120 - val_accuracy: 0.7069\n",
      "Epoch 19/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0002 - accuracy: 0.7084 - val_loss: 0.9946 - val_accuracy: 0.7111\n",
      "Epoch 20/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9831 - accuracy: 0.7128 - val_loss: 0.9731 - val_accuracy: 0.7174\n",
      "Epoch 21/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9635 - accuracy: 0.7192 - val_loss: 0.9590 - val_accuracy: 0.7208\n",
      "Epoch 22/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9474 - accuracy: 0.7252 - val_loss: 0.9406 - val_accuracy: 0.7277\n",
      "Epoch 23/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9318 - accuracy: 0.7276 - val_loss: 0.9326 - val_accuracy: 0.7311\n",
      "Epoch 24/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.9173 - accuracy: 0.7322 - val_loss: 0.9144 - val_accuracy: 0.7353\n",
      "Epoch 25/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9036 - accuracy: 0.7380 - val_loss: 0.9000 - val_accuracy: 0.7396\n",
      "Epoch 26/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8896 - accuracy: 0.7417 - val_loss: 0.8889 - val_accuracy: 0.7419\n",
      "Epoch 27/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8769 - accuracy: 0.7451 - val_loss: 0.8767 - val_accuracy: 0.7467\n",
      "Epoch 28/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8654 - accuracy: 0.7483 - val_loss: 0.8636 - val_accuracy: 0.7503\n",
      "Epoch 29/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8543 - accuracy: 0.7515 - val_loss: 0.8527 - val_accuracy: 0.7539\n",
      "Epoch 30/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8453 - accuracy: 0.7540 - val_loss: 0.8475 - val_accuracy: 0.7555\n",
      "Epoch 31/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8330 - accuracy: 0.7588 - val_loss: 0.8331 - val_accuracy: 0.7606\n",
      "Epoch 32/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8218 - accuracy: 0.7612 - val_loss: 0.8339 - val_accuracy: 0.7610\n",
      "Epoch 33/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8136 - accuracy: 0.7647 - val_loss: 0.8129 - val_accuracy: 0.7665\n",
      "Epoch 34/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.8040 - accuracy: 0.7677 - val_loss: 0.8083 - val_accuracy: 0.7664\n",
      "Epoch 35/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.7944 - accuracy: 0.7703 - val_loss: 0.8009 - val_accuracy: 0.7697\n",
      "Epoch 36/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7857 - accuracy: 0.7725 - val_loss: 0.7923 - val_accuracy: 0.7720\n",
      "Epoch 37/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.7779 - accuracy: 0.7760 - val_loss: 0.7881 - val_accuracy: 0.7708\n",
      "Epoch 38/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.7696 - accuracy: 0.7780 - val_loss: 0.7796 - val_accuracy: 0.7757\n",
      "Epoch 39/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.7601 - accuracy: 0.7792 - val_loss: 0.7698 - val_accuracy: 0.7790\n",
      "Epoch 40/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.7547 - accuracy: 0.7819 - val_loss: 0.7654 - val_accuracy: 0.7795\n",
      "Epoch 41/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7466 - accuracy: 0.7845 - val_loss: 0.7622 - val_accuracy: 0.7789\n",
      "Epoch 42/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.7394 - accuracy: 0.7866 - val_loss: 0.7514 - val_accuracy: 0.7851\n",
      "Epoch 43/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.7322 - accuracy: 0.7871 - val_loss: 0.7423 - val_accuracy: 0.7874\n",
      "Epoch 44/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.7252 - accuracy: 0.7912 - val_loss: 0.7374 - val_accuracy: 0.7883\n",
      "Epoch 45/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7201 - accuracy: 0.7915 - val_loss: 0.7345 - val_accuracy: 0.7868\n",
      "Epoch 46/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7137 - accuracy: 0.7948 - val_loss: 0.7277 - val_accuracy: 0.7909\n",
      "Epoch 47/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7061 - accuracy: 0.7961 - val_loss: 0.7240 - val_accuracy: 0.7923\n",
      "Epoch 48/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7018 - accuracy: 0.7973 - val_loss: 0.7138 - val_accuracy: 0.7954\n",
      "Epoch 49/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.6955 - accuracy: 0.8000 - val_loss: 0.7100 - val_accuracy: 0.7944\n",
      "Epoch 50/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.6887 - accuracy: 0.8021 - val_loss: 0.7045 - val_accuracy: 0.7994\n",
      "Epoch 51/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6841 - accuracy: 0.8018 - val_loss: 0.7021 - val_accuracy: 0.7974\n",
      "Epoch 52/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6778 - accuracy: 0.8040 - val_loss: 0.6956 - val_accuracy: 0.7997\n",
      "Epoch 53/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.6741 - accuracy: 0.8059 - val_loss: 0.6881 - val_accuracy: 0.8027\n",
      "Epoch 54/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6670 - accuracy: 0.8080 - val_loss: 0.6814 - val_accuracy: 0.8059\n",
      "Epoch 55/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.6620 - accuracy: 0.8098 - val_loss: 0.6773 - val_accuracy: 0.8074\n",
      "Epoch 56/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.6572 - accuracy: 0.8106 - val_loss: 0.6781 - val_accuracy: 0.8054\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 2s 11ms/step - loss: 0.6514 - accuracy: 0.8132 - val_loss: 0.6684 - val_accuracy: 0.8098\n",
      "Epoch 58/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.6458 - accuracy: 0.8142 - val_loss: 0.6686 - val_accuracy: 0.8088\n",
      "Epoch 59/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6418 - accuracy: 0.8174 - val_loss: 0.6607 - val_accuracy: 0.8122\n",
      "Epoch 60/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.6375 - accuracy: 0.8169 - val_loss: 0.6557 - val_accuracy: 0.8130\n",
      "Epoch 61/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.6341 - accuracy: 0.8179 - val_loss: 0.6626 - val_accuracy: 0.8102\n",
      "Epoch 62/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.6288 - accuracy: 0.8198 - val_loss: 0.6490 - val_accuracy: 0.8141\n",
      "Epoch 63/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.6238 - accuracy: 0.8191 - val_loss: 0.6465 - val_accuracy: 0.8168\n",
      "Epoch 64/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.6207 - accuracy: 0.8225 - val_loss: 0.6404 - val_accuracy: 0.8184\n",
      "Epoch 65/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.6162 - accuracy: 0.8235 - val_loss: 0.6409 - val_accuracy: 0.8179\n",
      "Epoch 66/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6117 - accuracy: 0.8271 - val_loss: 0.6352 - val_accuracy: 0.8181\n",
      "Epoch 67/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6069 - accuracy: 0.8275 - val_loss: 0.6325 - val_accuracy: 0.8199\n",
      "Epoch 68/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6037 - accuracy: 0.8275 - val_loss: 0.6295 - val_accuracy: 0.8210\n",
      "Epoch 69/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6007 - accuracy: 0.8285 - val_loss: 0.6209 - val_accuracy: 0.8249\n",
      "Epoch 70/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5946 - accuracy: 0.8305 - val_loss: 0.6230 - val_accuracy: 0.8226\n",
      "Epoch 71/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5922 - accuracy: 0.8316 - val_loss: 0.6154 - val_accuracy: 0.8271\n",
      "Epoch 72/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5888 - accuracy: 0.8315 - val_loss: 0.6128 - val_accuracy: 0.8261\n",
      "Epoch 73/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.5840 - accuracy: 0.8348 - val_loss: 0.6145 - val_accuracy: 0.8244\n",
      "Epoch 74/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.5803 - accuracy: 0.8342 - val_loss: 0.6064 - val_accuracy: 0.8289\n",
      "Epoch 75/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.5762 - accuracy: 0.8365 - val_loss: 0.6040 - val_accuracy: 0.8271\n",
      "Epoch 76/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5749 - accuracy: 0.8345 - val_loss: 0.5967 - val_accuracy: 0.8319\n",
      "Epoch 77/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5707 - accuracy: 0.8367 - val_loss: 0.5964 - val_accuracy: 0.8314\n",
      "Epoch 78/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5635 - accuracy: 0.8401 - val_loss: 0.5936 - val_accuracy: 0.8321\n",
      "Epoch 79/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.5645 - accuracy: 0.8389 - val_loss: 0.5877 - val_accuracy: 0.8360\n",
      "Epoch 80/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5588 - accuracy: 0.8410 - val_loss: 0.5903 - val_accuracy: 0.8322\n",
      "Epoch 81/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5570 - accuracy: 0.8403 - val_loss: 0.5870 - val_accuracy: 0.8332\n",
      "Epoch 82/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5539 - accuracy: 0.8422 - val_loss: 0.5833 - val_accuracy: 0.8356\n",
      "Epoch 83/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.5497 - accuracy: 0.8441 - val_loss: 0.5850 - val_accuracy: 0.8340\n",
      "Epoch 84/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5462 - accuracy: 0.8437 - val_loss: 0.5771 - val_accuracy: 0.8369\n",
      "Epoch 85/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5435 - accuracy: 0.8451 - val_loss: 0.5796 - val_accuracy: 0.8355\n",
      "Epoch 86/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5404 - accuracy: 0.8453 - val_loss: 0.5811 - val_accuracy: 0.8334\n",
      "Epoch 87/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5357 - accuracy: 0.8484 - val_loss: 0.5689 - val_accuracy: 0.8382\n",
      "Epoch 88/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5335 - accuracy: 0.8488 - val_loss: 0.5643 - val_accuracy: 0.8404\n",
      "Epoch 89/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5316 - accuracy: 0.8489 - val_loss: 0.5708 - val_accuracy: 0.8378\n",
      "Epoch 90/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5293 - accuracy: 0.8498 - val_loss: 0.5590 - val_accuracy: 0.8434\n",
      "Epoch 91/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5267 - accuracy: 0.8498 - val_loss: 0.5577 - val_accuracy: 0.8425\n",
      "Epoch 92/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.5231 - accuracy: 0.8516 - val_loss: 0.5591 - val_accuracy: 0.8430\n",
      "Epoch 93/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5190 - accuracy: 0.8546 - val_loss: 0.5559 - val_accuracy: 0.8428\n",
      "Epoch 94/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.5180 - accuracy: 0.8524 - val_loss: 0.5503 - val_accuracy: 0.8442\n",
      "Epoch 95/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5141 - accuracy: 0.8543 - val_loss: 0.5568 - val_accuracy: 0.8423\n",
      "Epoch 96/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5105 - accuracy: 0.8538 - val_loss: 0.5452 - val_accuracy: 0.8463\n",
      "Epoch 97/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5104 - accuracy: 0.8550 - val_loss: 0.5484 - val_accuracy: 0.8455\n",
      "Epoch 98/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.5056 - accuracy: 0.8563 - val_loss: 0.5391 - val_accuracy: 0.8491\n",
      "Epoch 99/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.5039 - accuracy: 0.8566 - val_loss: 0.5372 - val_accuracy: 0.8505\n",
      "Epoch 100/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.4998 - accuracy: 0.8592 - val_loss: 0.5403 - val_accuracy: 0.8472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18ab0aedc88>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd=optimizers.SGD(learning_rate=0.0001,momentum=0.9)\n",
    "model1.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model1.fit(X_train,y_train,validation_data=(X_val,y_val),batch_size=200,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Adam optimizer with learning rate=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.5774 - accuracy: 0.8300 - val_loss: 0.7341 - val_accuracy: 0.7741\n",
      "Epoch 2/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.5423 - accuracy: 0.8378 - val_loss: 0.7047 - val_accuracy: 0.7871\n",
      "Epoch 3/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.5179 - accuracy: 0.8469 - val_loss: 0.7166 - val_accuracy: 0.7843\n",
      "Epoch 4/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.4930 - accuracy: 0.8530 - val_loss: 0.6171 - val_accuracy: 0.8098\n",
      "Epoch 5/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.4737 - accuracy: 0.8592 - val_loss: 0.7604 - val_accuracy: 0.7668\n",
      "Epoch 6/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.4530 - accuracy: 0.8666 - val_loss: 0.6804 - val_accuracy: 0.7894\n",
      "Epoch 7/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.4271 - accuracy: 0.8766 - val_loss: 0.6918 - val_accuracy: 0.7828\n",
      "Epoch 8/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.4160 - accuracy: 0.8761 - val_loss: 0.6169 - val_accuracy: 0.8108\n",
      "Epoch 9/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.4040 - accuracy: 0.8800 - val_loss: 0.6480 - val_accuracy: 0.7974\n",
      "Epoch 10/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.3855 - accuracy: 0.8859 - val_loss: 0.8700 - val_accuracy: 0.7307\n",
      "Epoch 11/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.3715 - accuracy: 0.8909 - val_loss: 0.6057 - val_accuracy: 0.8138\n",
      "Epoch 12/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.3605 - accuracy: 0.8924 - val_loss: 0.5269 - val_accuracy: 0.8418\n",
      "Epoch 13/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.3496 - accuracy: 0.8973 - val_loss: 0.5799 - val_accuracy: 0.8249\n",
      "Epoch 14/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.3366 - accuracy: 0.9017 - val_loss: 0.5546 - val_accuracy: 0.8295\n",
      "Epoch 15/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.3291 - accuracy: 0.9053 - val_loss: 0.5287 - val_accuracy: 0.8369\n",
      "Epoch 16/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.3187 - accuracy: 0.9076 - val_loss: 0.4610 - val_accuracy: 0.8620\n",
      "Epoch 17/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.3113 - accuracy: 0.9093 - val_loss: 0.6232 - val_accuracy: 0.8005\n",
      "Epoch 18/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.3033 - accuracy: 0.9111 - val_loss: 0.5562 - val_accuracy: 0.8216\n",
      "Epoch 19/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.2957 - accuracy: 0.9131 - val_loss: 0.6075 - val_accuracy: 0.8099\n",
      "Epoch 20/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.2876 - accuracy: 0.9159 - val_loss: 0.5949 - val_accuracy: 0.8203\n",
      "Epoch 21/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.2765 - accuracy: 0.9191 - val_loss: 0.5440 - val_accuracy: 0.8321\n",
      "Epoch 22/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.2745 - accuracy: 0.9185 - val_loss: 0.5603 - val_accuracy: 0.8286\n",
      "Epoch 23/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.2586 - accuracy: 0.9257 - val_loss: 0.5595 - val_accuracy: 0.8307\n",
      "Epoch 24/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.2501 - accuracy: 0.9270 - val_loss: 0.6987 - val_accuracy: 0.7925\n",
      "Epoch 25/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.2475 - accuracy: 0.9283 - val_loss: 0.5729 - val_accuracy: 0.8255\n",
      "Epoch 26/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.2397 - accuracy: 0.9297 - val_loss: 0.5384 - val_accuracy: 0.8379\n",
      "Epoch 27/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.2405 - accuracy: 0.9296 - val_loss: 0.6764 - val_accuracy: 0.8054\n",
      "Epoch 28/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.2291 - accuracy: 0.9342 - val_loss: 0.5448 - val_accuracy: 0.8334\n",
      "Epoch 29/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.2253 - accuracy: 0.9342 - val_loss: 0.4775 - val_accuracy: 0.8558\n",
      "Epoch 30/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.2212 - accuracy: 0.9374 - val_loss: 0.4817 - val_accuracy: 0.8552\n",
      "Epoch 31/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.2084 - accuracy: 0.9399 - val_loss: 0.5317 - val_accuracy: 0.8370\n",
      "Epoch 32/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.2082 - accuracy: 0.9407 - val_loss: 0.4698 - val_accuracy: 0.8601\n",
      "Epoch 33/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.2032 - accuracy: 0.9418 - val_loss: 0.5545 - val_accuracy: 0.8371\n",
      "Epoch 34/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.1976 - accuracy: 0.9421 - val_loss: 0.5671 - val_accuracy: 0.8278\n",
      "Epoch 35/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.1910 - accuracy: 0.9451 - val_loss: 0.4385 - val_accuracy: 0.8691\n",
      "Epoch 36/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1870 - accuracy: 0.9460 - val_loss: 0.4692 - val_accuracy: 0.8588\n",
      "Epoch 37/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1817 - accuracy: 0.9483 - val_loss: 0.4839 - val_accuracy: 0.8555\n",
      "Epoch 38/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1749 - accuracy: 0.9510 - val_loss: 0.4900 - val_accuracy: 0.8547\n",
      "Epoch 39/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1660 - accuracy: 0.9535 - val_loss: 0.5186 - val_accuracy: 0.8470\n",
      "Epoch 40/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1651 - accuracy: 0.9527 - val_loss: 0.3904 - val_accuracy: 0.8858\n",
      "Epoch 41/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1610 - accuracy: 0.9554 - val_loss: 0.4370 - val_accuracy: 0.8719\n",
      "Epoch 42/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1557 - accuracy: 0.9557 - val_loss: 0.4710 - val_accuracy: 0.8625\n",
      "Epoch 43/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1539 - accuracy: 0.9572 - val_loss: 0.3989 - val_accuracy: 0.8824\n",
      "Epoch 44/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1488 - accuracy: 0.9590 - val_loss: 0.4143 - val_accuracy: 0.8785\n",
      "Epoch 45/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1464 - accuracy: 0.9591 - val_loss: 0.3919 - val_accuracy: 0.8865\n",
      "Epoch 46/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1427 - accuracy: 0.9600 - val_loss: 0.4899 - val_accuracy: 0.8559\n",
      "Epoch 47/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1447 - accuracy: 0.9591 - val_loss: 0.4370 - val_accuracy: 0.8748\n",
      "Epoch 48/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1435 - accuracy: 0.9591 - val_loss: 0.5349 - val_accuracy: 0.8488\n",
      "Epoch 49/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1409 - accuracy: 0.9600 - val_loss: 0.4862 - val_accuracy: 0.8607\n",
      "Epoch 50/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1379 - accuracy: 0.9614 - val_loss: 0.4199 - val_accuracy: 0.8778\n",
      "Epoch 51/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1323 - accuracy: 0.9628 - val_loss: 0.5062 - val_accuracy: 0.8513\n",
      "Epoch 52/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1363 - accuracy: 0.9618 - val_loss: 0.4529 - val_accuracy: 0.8672\n",
      "Epoch 53/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.1395 - accuracy: 0.9586 - val_loss: 0.5317 - val_accuracy: 0.8521\n",
      "Epoch 54/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.1267 - accuracy: 0.9637 - val_loss: 0.5207 - val_accuracy: 0.8585\n",
      "Epoch 55/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1220 - accuracy: 0.9651 - val_loss: 0.4184 - val_accuracy: 0.8812\n",
      "Epoch 56/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1205 - accuracy: 0.9655 - val_loss: 0.5658 - val_accuracy: 0.8458\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1163 - accuracy: 0.9683 - val_loss: 0.4933 - val_accuracy: 0.8657\n",
      "Epoch 58/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1094 - accuracy: 0.9710 - val_loss: 0.5142 - val_accuracy: 0.8575\n",
      "Epoch 59/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1081 - accuracy: 0.9704 - val_loss: 0.4780 - val_accuracy: 0.8684\n",
      "Epoch 60/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1100 - accuracy: 0.9690 - val_loss: 0.5246 - val_accuracy: 0.8540\n",
      "Epoch 61/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.1106 - accuracy: 0.9689 - val_loss: 0.3685 - val_accuracy: 0.8969\n",
      "Epoch 62/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1061 - accuracy: 0.9708 - val_loss: 0.4795 - val_accuracy: 0.8746\n",
      "Epoch 63/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.1062 - accuracy: 0.9707 - val_loss: 0.4628 - val_accuracy: 0.8731\n",
      "Epoch 64/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0991 - accuracy: 0.9739 - val_loss: 0.3758 - val_accuracy: 0.8952\n",
      "Epoch 65/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1002 - accuracy: 0.9719 - val_loss: 0.6119 - val_accuracy: 0.8317\n",
      "Epoch 66/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.1079 - accuracy: 0.9693 - val_loss: 0.4785 - val_accuracy: 0.8676\n",
      "Epoch 67/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.0956 - accuracy: 0.9735 - val_loss: 0.4388 - val_accuracy: 0.8867\n",
      "Epoch 68/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.0896 - accuracy: 0.9755 - val_loss: 0.4109 - val_accuracy: 0.8852\n",
      "Epoch 69/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0898 - accuracy: 0.9761 - val_loss: 0.5428 - val_accuracy: 0.8561\n",
      "Epoch 70/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.0887 - accuracy: 0.9762 - val_loss: 0.4825 - val_accuracy: 0.8705\n",
      "Epoch 71/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.0892 - accuracy: 0.9754 - val_loss: 0.4442 - val_accuracy: 0.8855\n",
      "Epoch 72/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0829 - accuracy: 0.9778 - val_loss: 0.4641 - val_accuracy: 0.8755\n",
      "Epoch 73/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.0881 - accuracy: 0.9759 - val_loss: 0.4277 - val_accuracy: 0.8890\n",
      "Epoch 74/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0806 - accuracy: 0.9787 - val_loss: 0.4941 - val_accuracy: 0.8633\n",
      "Epoch 75/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0856 - accuracy: 0.9770 - val_loss: 0.4737 - val_accuracy: 0.8685\n",
      "Epoch 76/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0796 - accuracy: 0.9788 - val_loss: 0.4777 - val_accuracy: 0.8801\n",
      "Epoch 77/100\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.0745 - accuracy: 0.9798 - val_loss: 0.5437 - val_accuracy: 0.8619\n",
      "Epoch 78/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0820 - accuracy: 0.9772 - val_loss: 0.5890 - val_accuracy: 0.8472\n",
      "Epoch 79/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0816 - accuracy: 0.9772 - val_loss: 0.4859 - val_accuracy: 0.8724\n",
      "Epoch 80/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0819 - accuracy: 0.9768 - val_loss: 0.3869 - val_accuracy: 0.8942\n",
      "Epoch 81/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0753 - accuracy: 0.9799 - val_loss: 0.5707 - val_accuracy: 0.8579\n",
      "Epoch 82/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0745 - accuracy: 0.9797 - val_loss: 0.4384 - val_accuracy: 0.8834\n",
      "Epoch 83/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0834 - accuracy: 0.9764 - val_loss: 0.4425 - val_accuracy: 0.8854\n",
      "Epoch 84/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.0712 - accuracy: 0.9817 - val_loss: 0.4366 - val_accuracy: 0.8829\n",
      "Epoch 85/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.0668 - accuracy: 0.9827 - val_loss: 0.3607 - val_accuracy: 0.9056\n",
      "Epoch 86/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0704 - accuracy: 0.9815 - val_loss: 0.5323 - val_accuracy: 0.8659\n",
      "Epoch 87/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.0764 - accuracy: 0.9799 - val_loss: 0.5279 - val_accuracy: 0.8684\n",
      "Epoch 88/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0706 - accuracy: 0.9813 - val_loss: 0.4662 - val_accuracy: 0.8795\n",
      "Epoch 89/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0729 - accuracy: 0.9792 - val_loss: 0.4889 - val_accuracy: 0.8680\n",
      "Epoch 90/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.0688 - accuracy: 0.9809 - val_loss: 0.4988 - val_accuracy: 0.8730\n",
      "Epoch 91/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0669 - accuracy: 0.9810 - val_loss: 0.4490 - val_accuracy: 0.8784\n",
      "Epoch 92/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0708 - accuracy: 0.9806 - val_loss: 0.4470 - val_accuracy: 0.8850\n",
      "Epoch 93/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0697 - accuracy: 0.9805 - val_loss: 0.3960 - val_accuracy: 0.8954\n",
      "Epoch 94/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.0639 - accuracy: 0.9822 - val_loss: 0.4779 - val_accuracy: 0.8778\n",
      "Epoch 95/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.0633 - accuracy: 0.9829 - val_loss: 0.4743 - val_accuracy: 0.8792\n",
      "Epoch 96/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0606 - accuracy: 0.9837 - val_loss: 0.5608 - val_accuracy: 0.8624\n",
      "Epoch 97/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0617 - accuracy: 0.9837 - val_loss: 0.4103 - val_accuracy: 0.8963\n",
      "Epoch 98/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0565 - accuracy: 0.9845 - val_loss: 0.5412 - val_accuracy: 0.8659\n",
      "Epoch 99/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.0600 - accuracy: 0.9842 - val_loss: 0.5418 - val_accuracy: 0.8662\n",
      "Epoch 100/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.0700 - accuracy: 0.9788 - val_loss: 0.4654 - val_accuracy: 0.8831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18ad2a14508>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam=optimizers.Adam(learning_rate=0.0001)\n",
    "model1.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model1.fit(X_train,y_train,validation_data=(X_val,y_val),batch_size=200,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch normalization using adam optimizer is giving better results than using SGD optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Batch Normalization and Drop out for training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Initilize the Neural Network Classifier\n",
    "model2=Sequential()\n",
    "\n",
    "# Input Layer\n",
    "# Adding Input Layer and activation function ReLu\n",
    "model2.add(Dense(512,input_shape=(1024,),activation='relu'))\n",
    "\n",
    "#Adding BatchNormalization Layer\n",
    "model2.add(BatchNormalization())\n",
    "\n",
    "#Adding Dropout Layer\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "# Hidden Layer\n",
    "# Adding Input Layer and activation function ReLu\n",
    "model2.add(Dense(512,activation='relu'))\n",
    "\n",
    "#Adding BatchNormalization Layer\n",
    "model2.add(BatchNormalization())\n",
    "\n",
    "#Adding Dropout Layer\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "# Output Layer\n",
    "# Adding output layer which is of 10 nodes and activation function softmax,because we have multiclass classification\n",
    "model2.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 796,682\n",
      "Trainable params: 794,634\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SGD optimizer with learning rate=0.0001 and momentum=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 3.4514 - accuracy: 0.1124 - val_loss: 2.3218 - val_accuracy: 0.1249\n",
      "Epoch 2/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 3.2028 - accuracy: 0.1253 - val_loss: 2.2250 - val_accuracy: 0.1894\n",
      "Epoch 3/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 3.0678 - accuracy: 0.1429 - val_loss: 2.0853 - val_accuracy: 0.2756\n",
      "Epoch 4/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 2.9358 - accuracy: 0.1558 - val_loss: 1.9855 - val_accuracy: 0.3296\n",
      "Epoch 5/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 2.8222 - accuracy: 0.1727 - val_loss: 1.9053 - val_accuracy: 0.3589\n",
      "Epoch 6/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 2.7149 - accuracy: 0.1873 - val_loss: 1.8308 - val_accuracy: 0.4076\n",
      "Epoch 7/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 2.6106 - accuracy: 0.2034 - val_loss: 1.7593 - val_accuracy: 0.4359\n",
      "Epoch 8/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 2.5266 - accuracy: 0.2211 - val_loss: 1.7120 - val_accuracy: 0.4579\n",
      "Epoch 9/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 2.4308 - accuracy: 0.2402 - val_loss: 1.6643 - val_accuracy: 0.4848\n",
      "Epoch 10/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 2.3730 - accuracy: 0.2558 - val_loss: 1.6159 - val_accuracy: 0.5002\n",
      "Epoch 11/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 2.2912 - accuracy: 0.2649 - val_loss: 1.5697 - val_accuracy: 0.5217\n",
      "Epoch 12/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 2.2259 - accuracy: 0.2850 - val_loss: 1.5218 - val_accuracy: 0.5378\n",
      "Epoch 13/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 2.1765 - accuracy: 0.2990 - val_loss: 1.4895 - val_accuracy: 0.5544\n",
      "Epoch 14/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 2.1199 - accuracy: 0.3129 - val_loss: 1.4550 - val_accuracy: 0.5695\n",
      "Epoch 15/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 2.0671 - accuracy: 0.3249 - val_loss: 1.4266 - val_accuracy: 0.5799\n",
      "Epoch 16/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 2.0205 - accuracy: 0.3366 - val_loss: 1.4000 - val_accuracy: 0.5892\n",
      "Epoch 17/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.9827 - accuracy: 0.3486 - val_loss: 1.3693 - val_accuracy: 0.5979\n",
      "Epoch 18/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.9373 - accuracy: 0.3593 - val_loss: 1.3401 - val_accuracy: 0.6116\n",
      "Epoch 19/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.8992 - accuracy: 0.3736 - val_loss: 1.3255 - val_accuracy: 0.6160\n",
      "Epoch 20/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.8700 - accuracy: 0.3813 - val_loss: 1.2976 - val_accuracy: 0.6242\n",
      "Epoch 21/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.8283 - accuracy: 0.3912 - val_loss: 1.2827 - val_accuracy: 0.6277\n",
      "Epoch 22/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.7932 - accuracy: 0.4028 - val_loss: 1.2617 - val_accuracy: 0.6360\n",
      "Epoch 23/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.7742 - accuracy: 0.4106 - val_loss: 1.2434 - val_accuracy: 0.6423\n",
      "Epoch 24/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.7381 - accuracy: 0.4218 - val_loss: 1.2319 - val_accuracy: 0.6440\n",
      "Epoch 25/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.7142 - accuracy: 0.4299 - val_loss: 1.2166 - val_accuracy: 0.6465\n",
      "Epoch 26/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.6972 - accuracy: 0.4361 - val_loss: 1.1991 - val_accuracy: 0.6568\n",
      "Epoch 27/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.6722 - accuracy: 0.4451 - val_loss: 1.1841 - val_accuracy: 0.6597\n",
      "Epoch 28/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.6453 - accuracy: 0.4508 - val_loss: 1.1678 - val_accuracy: 0.6658\n",
      "Epoch 29/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.6212 - accuracy: 0.4605 - val_loss: 1.1548 - val_accuracy: 0.6680\n",
      "Epoch 30/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.6065 - accuracy: 0.4644 - val_loss: 1.1515 - val_accuracy: 0.6697\n",
      "Epoch 31/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.5814 - accuracy: 0.4756 - val_loss: 1.1374 - val_accuracy: 0.6740\n",
      "Epoch 32/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.5680 - accuracy: 0.4829 - val_loss: 1.1239 - val_accuracy: 0.6779\n",
      "Epoch 33/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.5531 - accuracy: 0.4883 - val_loss: 1.1075 - val_accuracy: 0.6813\n",
      "Epoch 34/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.5348 - accuracy: 0.4951 - val_loss: 1.1022 - val_accuracy: 0.6845\n",
      "Epoch 35/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.5167 - accuracy: 0.4972 - val_loss: 1.0931 - val_accuracy: 0.6897\n",
      "Epoch 36/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.5055 - accuracy: 0.5022 - val_loss: 1.0875 - val_accuracy: 0.6892\n",
      "Epoch 37/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.4871 - accuracy: 0.5085 - val_loss: 1.0768 - val_accuracy: 0.6923\n",
      "Epoch 38/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.4691 - accuracy: 0.5148 - val_loss: 1.0614 - val_accuracy: 0.6986\n",
      "Epoch 39/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.4679 - accuracy: 0.5165 - val_loss: 1.0586 - val_accuracy: 0.6961\n",
      "Epoch 40/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.4436 - accuracy: 0.5233 - val_loss: 1.0537 - val_accuracy: 0.6990\n",
      "Epoch 41/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.4417 - accuracy: 0.5234 - val_loss: 1.0435 - val_accuracy: 0.6992\n",
      "Epoch 42/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.4272 - accuracy: 0.5314 - val_loss: 1.0337 - val_accuracy: 0.7037\n",
      "Epoch 43/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.4151 - accuracy: 0.5339 - val_loss: 1.0273 - val_accuracy: 0.7061\n",
      "Epoch 44/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.4108 - accuracy: 0.5380 - val_loss: 1.0192 - val_accuracy: 0.7070\n",
      "Epoch 45/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.3973 - accuracy: 0.5410 - val_loss: 1.0182 - val_accuracy: 0.7085\n",
      "Epoch 46/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.3902 - accuracy: 0.5426 - val_loss: 1.0061 - val_accuracy: 0.7134\n",
      "Epoch 47/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.3798 - accuracy: 0.5460 - val_loss: 1.0052 - val_accuracy: 0.7121\n",
      "Epoch 48/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.3592 - accuracy: 0.5561 - val_loss: 0.9944 - val_accuracy: 0.7147\n",
      "Epoch 49/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.3606 - accuracy: 0.5533 - val_loss: 0.9886 - val_accuracy: 0.7152\n",
      "Epoch 50/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.3539 - accuracy: 0.5591 - val_loss: 0.9822 - val_accuracy: 0.7191\n",
      "Epoch 51/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.3359 - accuracy: 0.5641 - val_loss: 0.9827 - val_accuracy: 0.7185\n",
      "Epoch 52/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.3251 - accuracy: 0.5682 - val_loss: 0.9707 - val_accuracy: 0.7223\n",
      "Epoch 53/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.3184 - accuracy: 0.5694 - val_loss: 0.9659 - val_accuracy: 0.7229\n",
      "Epoch 54/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.3138 - accuracy: 0.5717 - val_loss: 0.9633 - val_accuracy: 0.7250\n",
      "Epoch 55/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.3035 - accuracy: 0.5758 - val_loss: 0.9561 - val_accuracy: 0.7257\n",
      "Epoch 56/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.3022 - accuracy: 0.5779 - val_loss: 0.9547 - val_accuracy: 0.7247\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 3s 12ms/step - loss: 1.2902 - accuracy: 0.5812 - val_loss: 0.9470 - val_accuracy: 0.7275\n",
      "Epoch 58/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.2748 - accuracy: 0.5877 - val_loss: 0.9446 - val_accuracy: 0.7286\n",
      "Epoch 59/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.2739 - accuracy: 0.5878 - val_loss: 0.9428 - val_accuracy: 0.7269\n",
      "Epoch 60/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.2659 - accuracy: 0.5906 - val_loss: 0.9307 - val_accuracy: 0.7327\n",
      "Epoch 61/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.2623 - accuracy: 0.5925 - val_loss: 0.9299 - val_accuracy: 0.7331\n",
      "Epoch 62/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.2508 - accuracy: 0.5944 - val_loss: 0.9212 - val_accuracy: 0.7355\n",
      "Epoch 63/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.2482 - accuracy: 0.5980 - val_loss: 0.9221 - val_accuracy: 0.7340\n",
      "Epoch 64/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.2430 - accuracy: 0.5966 - val_loss: 0.9152 - val_accuracy: 0.7369\n",
      "Epoch 65/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.2339 - accuracy: 0.6004 - val_loss: 0.9105 - val_accuracy: 0.7360\n",
      "Epoch 66/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.2326 - accuracy: 0.6028 - val_loss: 0.9089 - val_accuracy: 0.7381\n",
      "Epoch 67/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.2196 - accuracy: 0.6064 - val_loss: 0.9020 - val_accuracy: 0.7422\n",
      "Epoch 68/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.2177 - accuracy: 0.6065 - val_loss: 0.8997 - val_accuracy: 0.7424\n",
      "Epoch 69/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.2180 - accuracy: 0.6059 - val_loss: 0.9022 - val_accuracy: 0.7398\n",
      "Epoch 70/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.2151 - accuracy: 0.6091 - val_loss: 0.8916 - val_accuracy: 0.7440\n",
      "Epoch 71/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1996 - accuracy: 0.6134 - val_loss: 0.8888 - val_accuracy: 0.7436\n",
      "Epoch 72/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.2008 - accuracy: 0.6123 - val_loss: 0.8821 - val_accuracy: 0.7454\n",
      "Epoch 73/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1952 - accuracy: 0.6159 - val_loss: 0.8823 - val_accuracy: 0.7467\n",
      "Epoch 74/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1873 - accuracy: 0.6203 - val_loss: 0.8759 - val_accuracy: 0.7474\n",
      "Epoch 75/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.1859 - accuracy: 0.6185 - val_loss: 0.8771 - val_accuracy: 0.7467\n",
      "Epoch 76/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1856 - accuracy: 0.6216 - val_loss: 0.8714 - val_accuracy: 0.7497\n",
      "Epoch 77/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1757 - accuracy: 0.6249 - val_loss: 0.8709 - val_accuracy: 0.7472\n",
      "Epoch 78/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1737 - accuracy: 0.6234 - val_loss: 0.8658 - val_accuracy: 0.7492\n",
      "Epoch 79/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1726 - accuracy: 0.6257 - val_loss: 0.8634 - val_accuracy: 0.7513\n",
      "Epoch 80/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1621 - accuracy: 0.6297 - val_loss: 0.8596 - val_accuracy: 0.7523\n",
      "Epoch 81/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1629 - accuracy: 0.6287 - val_loss: 0.8547 - val_accuracy: 0.7523\n",
      "Epoch 82/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1590 - accuracy: 0.6289 - val_loss: 0.8514 - val_accuracy: 0.7563\n",
      "Epoch 83/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1506 - accuracy: 0.6328 - val_loss: 0.8502 - val_accuracy: 0.7539\n",
      "Epoch 84/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1445 - accuracy: 0.6370 - val_loss: 0.8435 - val_accuracy: 0.7566\n",
      "Epoch 85/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1460 - accuracy: 0.6359 - val_loss: 0.8414 - val_accuracy: 0.7577\n",
      "Epoch 86/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1388 - accuracy: 0.6352 - val_loss: 0.8432 - val_accuracy: 0.7566\n",
      "Epoch 87/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1339 - accuracy: 0.6366 - val_loss: 0.8345 - val_accuracy: 0.7603\n",
      "Epoch 88/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1377 - accuracy: 0.6388 - val_loss: 0.8318 - val_accuracy: 0.7596\n",
      "Epoch 89/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.1317 - accuracy: 0.6420 - val_loss: 0.8295 - val_accuracy: 0.7605\n",
      "Epoch 90/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1276 - accuracy: 0.6403 - val_loss: 0.8314 - val_accuracy: 0.7612\n",
      "Epoch 91/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1223 - accuracy: 0.6415 - val_loss: 0.8283 - val_accuracy: 0.7595\n",
      "Epoch 92/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1198 - accuracy: 0.6461 - val_loss: 0.8255 - val_accuracy: 0.7612\n",
      "Epoch 93/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1129 - accuracy: 0.6471 - val_loss: 0.8205 - val_accuracy: 0.7627\n",
      "Epoch 94/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1111 - accuracy: 0.6498 - val_loss: 0.8159 - val_accuracy: 0.7636\n",
      "Epoch 95/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1068 - accuracy: 0.6502 - val_loss: 0.8143 - val_accuracy: 0.7638\n",
      "Epoch 96/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1019 - accuracy: 0.6507 - val_loss: 0.8135 - val_accuracy: 0.7651\n",
      "Epoch 97/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.1023 - accuracy: 0.6503 - val_loss: 0.8097 - val_accuracy: 0.7660\n",
      "Epoch 98/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0992 - accuracy: 0.6513 - val_loss: 0.8093 - val_accuracy: 0.7651\n",
      "Epoch 99/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0933 - accuracy: 0.6528 - val_loss: 0.8049 - val_accuracy: 0.7667\n",
      "Epoch 100/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0904 - accuracy: 0.6560 - val_loss: 0.8042 - val_accuracy: 0.7672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18ab0a9e988>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd=optimizers.SGD(learning_rate=0.0001,momentum=0.9)\n",
    "model2.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model2.fit(X_train,y_train,validation_data=(X_val,y_val),batch_size=200,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Adam optimizer with learning rate=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.1499 - accuracy: 0.6327 - val_loss: 0.8851 - val_accuracy: 0.7403\n",
      "Epoch 2/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.1279 - accuracy: 0.6396 - val_loss: 0.8630 - val_accuracy: 0.7470\n",
      "Epoch 3/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.1016 - accuracy: 0.6528 - val_loss: 0.8869 - val_accuracy: 0.7249\n",
      "Epoch 4/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0824 - accuracy: 0.6580 - val_loss: 0.8641 - val_accuracy: 0.7360\n",
      "Epoch 5/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0727 - accuracy: 0.6627 - val_loss: 0.8233 - val_accuracy: 0.7510\n",
      "Epoch 6/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0409 - accuracy: 0.6732 - val_loss: 0.8095 - val_accuracy: 0.7606\n",
      "Epoch 7/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0272 - accuracy: 0.6762 - val_loss: 0.7863 - val_accuracy: 0.7651\n",
      "Epoch 8/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0077 - accuracy: 0.6840 - val_loss: 0.7957 - val_accuracy: 0.7612\n",
      "Epoch 9/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0049 - accuracy: 0.6865 - val_loss: 0.7783 - val_accuracy: 0.7674\n",
      "Epoch 10/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9805 - accuracy: 0.6916 - val_loss: 0.7603 - val_accuracy: 0.7718\n",
      "Epoch 11/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9658 - accuracy: 0.6985 - val_loss: 0.7233 - val_accuracy: 0.7861\n",
      "Epoch 12/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9636 - accuracy: 0.7000 - val_loss: 0.7428 - val_accuracy: 0.7783\n",
      "Epoch 13/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9553 - accuracy: 0.7023 - val_loss: 0.7397 - val_accuracy: 0.7785\n",
      "Epoch 14/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9362 - accuracy: 0.7070 - val_loss: 0.7196 - val_accuracy: 0.7894\n",
      "Epoch 15/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9379 - accuracy: 0.7103 - val_loss: 0.7119 - val_accuracy: 0.7887\n",
      "Epoch 16/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9267 - accuracy: 0.7100 - val_loss: 0.6913 - val_accuracy: 0.7927\n",
      "Epoch 17/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9196 - accuracy: 0.7129 - val_loss: 0.7101 - val_accuracy: 0.7869\n",
      "Epoch 18/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9059 - accuracy: 0.7175 - val_loss: 0.7065 - val_accuracy: 0.7876\n",
      "Epoch 19/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9036 - accuracy: 0.7196 - val_loss: 0.7028 - val_accuracy: 0.7890\n",
      "Epoch 20/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8925 - accuracy: 0.7243 - val_loss: 0.6964 - val_accuracy: 0.7916\n",
      "Epoch 21/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8839 - accuracy: 0.7253 - val_loss: 0.7129 - val_accuracy: 0.7827\n",
      "Epoch 22/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8763 - accuracy: 0.7287 - val_loss: 0.6848 - val_accuracy: 0.7956\n",
      "Epoch 23/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8695 - accuracy: 0.7307 - val_loss: 0.6654 - val_accuracy: 0.7998\n",
      "Epoch 24/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8694 - accuracy: 0.7288 - val_loss: 0.6929 - val_accuracy: 0.7879\n",
      "Epoch 25/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8615 - accuracy: 0.7332 - val_loss: 0.6743 - val_accuracy: 0.7987\n",
      "Epoch 26/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8552 - accuracy: 0.7361 - val_loss: 0.6783 - val_accuracy: 0.7947\n",
      "Epoch 27/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8514 - accuracy: 0.7346 - val_loss: 0.6567 - val_accuracy: 0.7986\n",
      "Epoch 28/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8365 - accuracy: 0.7395 - val_loss: 0.6744 - val_accuracy: 0.7914\n",
      "Epoch 29/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8360 - accuracy: 0.7400 - val_loss: 0.6996 - val_accuracy: 0.7851\n",
      "Epoch 30/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8372 - accuracy: 0.7424 - val_loss: 0.6685 - val_accuracy: 0.7951\n",
      "Epoch 31/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8266 - accuracy: 0.7431 - val_loss: 0.6638 - val_accuracy: 0.7966\n",
      "Epoch 32/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8193 - accuracy: 0.7460 - val_loss: 0.6246 - val_accuracy: 0.8123\n",
      "Epoch 33/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8167 - accuracy: 0.7462 - val_loss: 0.6082 - val_accuracy: 0.8193\n",
      "Epoch 34/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8148 - accuracy: 0.7468 - val_loss: 0.5842 - val_accuracy: 0.8239\n",
      "Epoch 35/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8101 - accuracy: 0.7487 - val_loss: 0.6288 - val_accuracy: 0.8069\n",
      "Epoch 36/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.8010 - accuracy: 0.7515 - val_loss: 0.5915 - val_accuracy: 0.8208\n",
      "Epoch 37/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7930 - accuracy: 0.7523 - val_loss: 0.6177 - val_accuracy: 0.8108\n",
      "Epoch 38/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7940 - accuracy: 0.7515 - val_loss: 0.6070 - val_accuracy: 0.8146\n",
      "Epoch 39/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7858 - accuracy: 0.7570 - val_loss: 0.5947 - val_accuracy: 0.8214\n",
      "Epoch 40/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7804 - accuracy: 0.7553 - val_loss: 0.5843 - val_accuracy: 0.8238\n",
      "Epoch 41/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7759 - accuracy: 0.7607 - val_loss: 0.5788 - val_accuracy: 0.8251\n",
      "Epoch 42/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7830 - accuracy: 0.7570 - val_loss: 0.5879 - val_accuracy: 0.8197\n",
      "Epoch 43/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7785 - accuracy: 0.7583 - val_loss: 0.5936 - val_accuracy: 0.8182\n",
      "Epoch 44/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7724 - accuracy: 0.7614 - val_loss: 0.5804 - val_accuracy: 0.8237\n",
      "Epoch 45/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7678 - accuracy: 0.7619 - val_loss: 0.6144 - val_accuracy: 0.8137\n",
      "Epoch 46/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.7652 - accuracy: 0.7619 - val_loss: 0.5798 - val_accuracy: 0.8226\n",
      "Epoch 47/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7573 - accuracy: 0.7629 - val_loss: 0.5820 - val_accuracy: 0.8210\n",
      "Epoch 48/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7539 - accuracy: 0.7656 - val_loss: 0.5920 - val_accuracy: 0.8160\n",
      "Epoch 49/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7517 - accuracy: 0.7649 - val_loss: 0.6086 - val_accuracy: 0.8128\n",
      "Epoch 50/100\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.7569 - accuracy: 0.7651 - val_loss: 0.6022 - val_accuracy: 0.8234\n",
      "Epoch 51/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7515 - accuracy: 0.7679 - val_loss: 0.5632 - val_accuracy: 0.8275\n",
      "Epoch 52/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7515 - accuracy: 0.7649 - val_loss: 0.5641 - val_accuracy: 0.8284\n",
      "Epoch 53/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7509 - accuracy: 0.7671 - val_loss: 0.6047 - val_accuracy: 0.8141\n",
      "Epoch 54/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7497 - accuracy: 0.7678 - val_loss: 0.5413 - val_accuracy: 0.8372\n",
      "Epoch 55/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7384 - accuracy: 0.7707 - val_loss: 0.5572 - val_accuracy: 0.8301\n",
      "Epoch 56/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.7366 - accuracy: 0.7718 - val_loss: 0.5467 - val_accuracy: 0.8368\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7324 - accuracy: 0.7722 - val_loss: 0.5465 - val_accuracy: 0.8381\n",
      "Epoch 58/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7296 - accuracy: 0.7728 - val_loss: 0.5638 - val_accuracy: 0.8272\n",
      "Epoch 59/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7329 - accuracy: 0.7741 - val_loss: 0.5521 - val_accuracy: 0.8373\n",
      "Epoch 60/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7325 - accuracy: 0.7718 - val_loss: 0.5315 - val_accuracy: 0.8390\n",
      "Epoch 61/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7197 - accuracy: 0.7777 - val_loss: 0.5278 - val_accuracy: 0.8414\n",
      "Epoch 62/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7238 - accuracy: 0.7755 - val_loss: 0.5623 - val_accuracy: 0.8275\n",
      "Epoch 63/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7213 - accuracy: 0.7765 - val_loss: 0.5370 - val_accuracy: 0.8358\n",
      "Epoch 64/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.7191 - accuracy: 0.7761 - val_loss: 0.5399 - val_accuracy: 0.8406\n",
      "Epoch 65/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.7151 - accuracy: 0.7767 - val_loss: 0.5258 - val_accuracy: 0.8410\n",
      "Epoch 66/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.7007 - accuracy: 0.7815 - val_loss: 0.5418 - val_accuracy: 0.8359\n",
      "Epoch 67/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7043 - accuracy: 0.7811 - val_loss: 0.5252 - val_accuracy: 0.8405\n",
      "Epoch 68/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.6984 - accuracy: 0.7826 - val_loss: 0.5476 - val_accuracy: 0.8307\n",
      "Epoch 69/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7009 - accuracy: 0.7818 - val_loss: 0.5230 - val_accuracy: 0.8411\n",
      "Epoch 70/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7076 - accuracy: 0.7802 - val_loss: 0.5483 - val_accuracy: 0.8336\n",
      "Epoch 71/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7024 - accuracy: 0.7824 - val_loss: 0.5048 - val_accuracy: 0.8482\n",
      "Epoch 72/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7015 - accuracy: 0.7840 - val_loss: 0.5266 - val_accuracy: 0.8443\n",
      "Epoch 73/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7013 - accuracy: 0.7807 - val_loss: 0.5515 - val_accuracy: 0.8383\n",
      "Epoch 74/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6872 - accuracy: 0.7871 - val_loss: 0.5010 - val_accuracy: 0.8508\n",
      "Epoch 75/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6910 - accuracy: 0.7838 - val_loss: 0.5214 - val_accuracy: 0.8419\n",
      "Epoch 76/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6815 - accuracy: 0.7872 - val_loss: 0.5165 - val_accuracy: 0.8461\n",
      "Epoch 77/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6892 - accuracy: 0.7866 - val_loss: 0.5201 - val_accuracy: 0.8457\n",
      "Epoch 78/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6800 - accuracy: 0.7886 - val_loss: 0.5071 - val_accuracy: 0.8478\n",
      "Epoch 79/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6693 - accuracy: 0.7911 - val_loss: 0.4991 - val_accuracy: 0.8500\n",
      "Epoch 80/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6859 - accuracy: 0.7887 - val_loss: 0.5103 - val_accuracy: 0.8441\n",
      "Epoch 81/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6815 - accuracy: 0.7893 - val_loss: 0.4984 - val_accuracy: 0.8529\n",
      "Epoch 82/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6794 - accuracy: 0.7890 - val_loss: 0.5065 - val_accuracy: 0.8459\n",
      "Epoch 83/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6776 - accuracy: 0.7887 - val_loss: 0.5182 - val_accuracy: 0.8469\n",
      "Epoch 84/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6816 - accuracy: 0.7882 - val_loss: 0.4955 - val_accuracy: 0.8514\n",
      "Epoch 85/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6785 - accuracy: 0.7892 - val_loss: 0.5123 - val_accuracy: 0.8431\n",
      "Epoch 86/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6783 - accuracy: 0.7890 - val_loss: 0.5060 - val_accuracy: 0.8471\n",
      "Epoch 87/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6733 - accuracy: 0.7904 - val_loss: 0.4869 - val_accuracy: 0.8543\n",
      "Epoch 88/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.6760 - accuracy: 0.7893 - val_loss: 0.5150 - val_accuracy: 0.8445\n",
      "Epoch 89/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6665 - accuracy: 0.7938 - val_loss: 0.4868 - val_accuracy: 0.8571\n",
      "Epoch 90/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6791 - accuracy: 0.7899 - val_loss: 0.5312 - val_accuracy: 0.8363\n",
      "Epoch 91/100\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.6715 - accuracy: 0.7896 - val_loss: 0.4909 - val_accuracy: 0.8526\n",
      "Epoch 92/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6668 - accuracy: 0.7913 - val_loss: 0.4923 - val_accuracy: 0.8487\n",
      "Epoch 93/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6625 - accuracy: 0.7927 - val_loss: 0.5023 - val_accuracy: 0.8485\n",
      "Epoch 94/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6668 - accuracy: 0.7939 - val_loss: 0.4951 - val_accuracy: 0.8529\n",
      "Epoch 95/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6723 - accuracy: 0.7895 - val_loss: 0.5124 - val_accuracy: 0.8489\n",
      "Epoch 96/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6592 - accuracy: 0.7935 - val_loss: 0.4812 - val_accuracy: 0.8534\n",
      "Epoch 97/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6607 - accuracy: 0.7919 - val_loss: 0.4839 - val_accuracy: 0.8544\n",
      "Epoch 98/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6588 - accuracy: 0.7944 - val_loss: 0.5096 - val_accuracy: 0.8493\n",
      "Epoch 99/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6640 - accuracy: 0.7945 - val_loss: 0.4857 - val_accuracy: 0.8518\n",
      "Epoch 100/100\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6531 - accuracy: 0.7958 - val_loss: 0.4831 - val_accuracy: 0.8540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18aadacc5c8>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam=optimizers.Adam(learning_rate=0.0001)\n",
    "model2.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model2.fit(X_train,y_train,validation_data=(X_val,y_val),batch_size=200,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model on validation data using Drop out layer is very low either using sgd or adam.we will try to train the Neural network using Batch Normalization only.The batch normalization using adam optimizer is giving better results than using SGD optimizer.So,we will use adam optimizer to test the Neural network on test data and we will predict the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing NN on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilize the Neural Network Classifier\n",
    "model_final=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Layer\n",
    "# Adding Input Layer and activation function ReLu\n",
    "model_final.add(Dense(512,input_shape=(1024,),activation='relu'))\n",
    "\n",
    "#Adding BatchNormalization Layer\n",
    "model_final.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden Layer\n",
    "# Adding Input Layer and activation function ReLu\n",
    "model_final.add(Dense(512,activation='relu'))\n",
    "\n",
    "#Adding BatchNormalization Layer\n",
    "model_final.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Layer\n",
    "# Adding output layer which is of 10 nodes and activation function softmax,because we have multiclass classification\n",
    "model_final.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Adam optimizer with leaning rate=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 1.6886 - accuracy: 0.4570 - val_loss: 1.8577 - val_accuracy: 0.3894\n",
      "Epoch 2/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 1.0623 - accuracy: 0.6842 - val_loss: 1.2076 - val_accuracy: 0.6271\n",
      "Epoch 3/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8802 - accuracy: 0.7425 - val_loss: 1.0266 - val_accuracy: 0.6817\n",
      "Epoch 4/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.7714 - accuracy: 0.7759 - val_loss: 0.9415 - val_accuracy: 0.7142\n",
      "Epoch 5/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.6967 - accuracy: 0.7995 - val_loss: 0.8784 - val_accuracy: 0.7323\n",
      "Epoch 6/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.6420 - accuracy: 0.8152 - val_loss: 0.9812 - val_accuracy: 0.6841\n",
      "Epoch 7/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.5982 - accuracy: 0.8276 - val_loss: 0.8480 - val_accuracy: 0.7379\n",
      "Epoch 8/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.5559 - accuracy: 0.8420 - val_loss: 0.7955 - val_accuracy: 0.7601\n",
      "Epoch 9/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5229 - accuracy: 0.8507 - val_loss: 0.7382 - val_accuracy: 0.7849\n",
      "Epoch 10/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5002 - accuracy: 0.8562 - val_loss: 1.0194 - val_accuracy: 0.6928\n",
      "Epoch 11/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4781 - accuracy: 0.8621 - val_loss: 0.7054 - val_accuracy: 0.7918\n",
      "Epoch 12/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4556 - accuracy: 0.8709 - val_loss: 0.7788 - val_accuracy: 0.7653\n",
      "Epoch 13/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4388 - accuracy: 0.8748 - val_loss: 0.7451 - val_accuracy: 0.7694\n",
      "Epoch 14/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4227 - accuracy: 0.8796 - val_loss: 0.8051 - val_accuracy: 0.7574\n",
      "Epoch 15/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.4042 - accuracy: 0.8863 - val_loss: 0.7434 - val_accuracy: 0.7743\n",
      "Epoch 16/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3934 - accuracy: 0.8865 - val_loss: 0.6719 - val_accuracy: 0.8022\n",
      "Epoch 17/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.3768 - accuracy: 0.8922 - val_loss: 0.8234 - val_accuracy: 0.7510\n",
      "Epoch 18/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3598 - accuracy: 0.8957 - val_loss: 0.6968 - val_accuracy: 0.7951\n",
      "Epoch 19/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3542 - accuracy: 0.8983 - val_loss: 0.7020 - val_accuracy: 0.7899\n",
      "Epoch 20/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3396 - accuracy: 0.9025 - val_loss: 0.6851 - val_accuracy: 0.7949\n",
      "Epoch 21/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3272 - accuracy: 0.9063 - val_loss: 0.7916 - val_accuracy: 0.7664\n",
      "Epoch 22/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3175 - accuracy: 0.9107 - val_loss: 0.6478 - val_accuracy: 0.8108\n",
      "Epoch 23/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3080 - accuracy: 0.9124 - val_loss: 0.7027 - val_accuracy: 0.7907\n",
      "Epoch 24/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3025 - accuracy: 0.9150 - val_loss: 0.6674 - val_accuracy: 0.8002\n",
      "Epoch 25/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.2937 - accuracy: 0.9169 - val_loss: 0.7226 - val_accuracy: 0.7864\n",
      "Epoch 26/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.2834 - accuracy: 0.9188 - val_loss: 0.6570 - val_accuracy: 0.8050\n",
      "Epoch 27/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.2726 - accuracy: 0.9217 - val_loss: 1.1427 - val_accuracy: 0.6878\n",
      "Epoch 28/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.2606 - accuracy: 0.9267 - val_loss: 0.7245 - val_accuracy: 0.7950\n",
      "Epoch 29/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.2566 - accuracy: 0.9279 - val_loss: 0.7469 - val_accuracy: 0.7873\n",
      "Epoch 30/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.2483 - accuracy: 0.9288 - val_loss: 0.6824 - val_accuracy: 0.8032\n",
      "Epoch 31/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.2411 - accuracy: 0.9318 - val_loss: 0.7083 - val_accuracy: 0.7962\n",
      "Epoch 32/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.2348 - accuracy: 0.9336 - val_loss: 0.7330 - val_accuracy: 0.7917\n",
      "Epoch 33/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.2245 - accuracy: 0.9360 - val_loss: 0.7502 - val_accuracy: 0.7874\n",
      "Epoch 34/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.2164 - accuracy: 0.9395 - val_loss: 0.8058 - val_accuracy: 0.7703\n",
      "Epoch 35/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.2133 - accuracy: 0.9417 - val_loss: 0.6957 - val_accuracy: 0.8014\n",
      "Epoch 36/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.2060 - accuracy: 0.9430 - val_loss: 0.6324 - val_accuracy: 0.8256\n",
      "Epoch 37/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1981 - accuracy: 0.9448 - val_loss: 0.7962 - val_accuracy: 0.7883\n",
      "Epoch 38/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1980 - accuracy: 0.9442 - val_loss: 0.7330 - val_accuracy: 0.7947\n",
      "Epoch 39/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1922 - accuracy: 0.9464 - val_loss: 0.7705 - val_accuracy: 0.7880\n",
      "Epoch 40/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1875 - accuracy: 0.9472 - val_loss: 0.6923 - val_accuracy: 0.8099\n",
      "Epoch 41/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1791 - accuracy: 0.9503 - val_loss: 0.6645 - val_accuracy: 0.8163\n",
      "Epoch 42/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1766 - accuracy: 0.9502 - val_loss: 0.7082 - val_accuracy: 0.8038\n",
      "Epoch 43/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1693 - accuracy: 0.9537 - val_loss: 0.7697 - val_accuracy: 0.7908\n",
      "Epoch 44/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1653 - accuracy: 0.9541 - val_loss: 0.7331 - val_accuracy: 0.8041\n",
      "Epoch 45/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1626 - accuracy: 0.9560 - val_loss: 0.7675 - val_accuracy: 0.8004\n",
      "Epoch 46/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1552 - accuracy: 0.9566 - val_loss: 0.7870 - val_accuracy: 0.7923\n",
      "Epoch 47/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1577 - accuracy: 0.9561 - val_loss: 0.7798 - val_accuracy: 0.7944\n",
      "Epoch 48/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1493 - accuracy: 0.9600 - val_loss: 0.7519 - val_accuracy: 0.7950\n",
      "Epoch 49/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1446 - accuracy: 0.9607 - val_loss: 0.7662 - val_accuracy: 0.8050\n",
      "Epoch 50/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1387 - accuracy: 0.9621 - val_loss: 0.8083 - val_accuracy: 0.7904\n",
      "Epoch 51/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1368 - accuracy: 0.9627 - val_loss: 0.8141 - val_accuracy: 0.7886\n",
      "Epoch 52/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1380 - accuracy: 0.9618 - val_loss: 0.6585 - val_accuracy: 0.8263\n",
      "Epoch 53/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1295 - accuracy: 0.9660 - val_loss: 0.7536 - val_accuracy: 0.8104\n",
      "Epoch 54/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1281 - accuracy: 0.9656 - val_loss: 0.7900 - val_accuracy: 0.7999\n",
      "Epoch 55/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1242 - accuracy: 0.9664 - val_loss: 0.7841 - val_accuracy: 0.8004\n",
      "Epoch 56/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1272 - accuracy: 0.9651 - val_loss: 0.8410 - val_accuracy: 0.7875\n",
      "Epoch 57/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1204 - accuracy: 0.9678 - val_loss: 0.7629 - val_accuracy: 0.8128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1189 - accuracy: 0.9683 - val_loss: 1.1221 - val_accuracy: 0.7472\n",
      "Epoch 59/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.1126 - accuracy: 0.9698 - val_loss: 0.9202 - val_accuracy: 0.7811\n",
      "Epoch 60/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.1125 - accuracy: 0.9695 - val_loss: 0.9139 - val_accuracy: 0.7850\n",
      "Epoch 61/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.1120 - accuracy: 0.9698 - val_loss: 0.8096 - val_accuracy: 0.7994\n",
      "Epoch 62/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.1068 - accuracy: 0.9712 - val_loss: 0.7738 - val_accuracy: 0.8103\n",
      "Epoch 63/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1108 - accuracy: 0.9697 - val_loss: 0.7757 - val_accuracy: 0.8126\n",
      "Epoch 64/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1025 - accuracy: 0.9727 - val_loss: 0.9039 - val_accuracy: 0.7805\n",
      "Epoch 65/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1064 - accuracy: 0.9703 - val_loss: 0.8554 - val_accuracy: 0.7945\n",
      "Epoch 66/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1060 - accuracy: 0.9710 - val_loss: 0.7479 - val_accuracy: 0.8179\n",
      "Epoch 67/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.1024 - accuracy: 0.9725 - val_loss: 0.9582 - val_accuracy: 0.7761\n",
      "Epoch 68/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.0929 - accuracy: 0.9749 - val_loss: 0.8425 - val_accuracy: 0.8058\n",
      "Epoch 69/100\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.0917 - accuracy: 0.9755 - val_loss: 0.8846 - val_accuracy: 0.8003\n",
      "Epoch 70/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0906 - accuracy: 0.9767 - val_loss: 0.7210 - val_accuracy: 0.8243\n",
      "Epoch 71/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0826 - accuracy: 0.9789 - val_loss: 0.8230 - val_accuracy: 0.8049\n",
      "Epoch 72/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0835 - accuracy: 0.9782 - val_loss: 0.7976 - val_accuracy: 0.8122\n",
      "Epoch 73/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0831 - accuracy: 0.9781 - val_loss: 0.7504 - val_accuracy: 0.8089\n",
      "Epoch 74/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0845 - accuracy: 0.9781 - val_loss: 0.9806 - val_accuracy: 0.7709\n",
      "Epoch 75/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0826 - accuracy: 0.9778 - val_loss: 0.8386 - val_accuracy: 0.8096\n",
      "Epoch 76/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0751 - accuracy: 0.9810 - val_loss: 0.7603 - val_accuracy: 0.8178\n",
      "Epoch 77/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0779 - accuracy: 0.9799 - val_loss: 0.9813 - val_accuracy: 0.7812\n",
      "Epoch 78/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0831 - accuracy: 0.9773 - val_loss: 0.8089 - val_accuracy: 0.8089\n",
      "Epoch 79/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0762 - accuracy: 0.9800 - val_loss: 0.8075 - val_accuracy: 0.8132\n",
      "Epoch 80/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0712 - accuracy: 0.9816 - val_loss: 0.7678 - val_accuracy: 0.8224\n",
      "Epoch 81/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0694 - accuracy: 0.9824 - val_loss: 0.8440 - val_accuracy: 0.8139\n",
      "Epoch 82/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0686 - accuracy: 0.9826 - val_loss: 0.8945 - val_accuracy: 0.7966\n",
      "Epoch 83/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0676 - accuracy: 0.9828 - val_loss: 1.0030 - val_accuracy: 0.7877\n",
      "Epoch 84/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0719 - accuracy: 0.9799 - val_loss: 0.8687 - val_accuracy: 0.8138\n",
      "Epoch 85/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0659 - accuracy: 0.9833 - val_loss: 0.8855 - val_accuracy: 0.8092\n",
      "Epoch 86/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0692 - accuracy: 0.9812 - val_loss: 0.8592 - val_accuracy: 0.8116\n",
      "Epoch 87/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0606 - accuracy: 0.9846 - val_loss: 1.0884 - val_accuracy: 0.7750\n",
      "Epoch 88/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0748 - accuracy: 0.9784 - val_loss: 0.8897 - val_accuracy: 0.8075\n",
      "Epoch 89/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0674 - accuracy: 0.9822 - val_loss: 0.9496 - val_accuracy: 0.7970\n",
      "Epoch 90/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0675 - accuracy: 0.9817 - val_loss: 0.8421 - val_accuracy: 0.8154\n",
      "Epoch 91/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0617 - accuracy: 0.9838 - val_loss: 0.9506 - val_accuracy: 0.7874\n",
      "Epoch 92/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0636 - accuracy: 0.9826 - val_loss: 0.9170 - val_accuracy: 0.8112\n",
      "Epoch 93/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0552 - accuracy: 0.9861 - val_loss: 0.8699 - val_accuracy: 0.8110\n",
      "Epoch 94/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0524 - accuracy: 0.9869 - val_loss: 0.9299 - val_accuracy: 0.8107\n",
      "Epoch 95/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0669 - accuracy: 0.9816 - val_loss: 0.9219 - val_accuracy: 0.8081\n",
      "Epoch 96/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0612 - accuracy: 0.9838 - val_loss: 0.8829 - val_accuracy: 0.8064\n",
      "Epoch 97/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0554 - accuracy: 0.9857 - val_loss: 0.8776 - val_accuracy: 0.8164\n",
      "Epoch 98/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0616 - accuracy: 0.9832 - val_loss: 0.9243 - val_accuracy: 0.8016\n",
      "Epoch 99/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0569 - accuracy: 0.9850 - val_loss: 0.8732 - val_accuracy: 0.8171\n",
      "Epoch 100/100\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.0530 - accuracy: 0.9863 - val_loss: 0.8268 - val_accuracy: 0.8208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18ad5b013c8>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam=optimizers.Adam(learning_rate=0.0001)\n",
    "model_final.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model_final.fit(X_train,y_train,validation_data=(X_test,y_test),batch_size=200,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 1s 1ms/step - loss: 0.8268 - accuracy: 0.8208: 0s - loss: 0.7990 - ac\n",
      "Test Accuracy on Testing data: 0.8208333253860474\n"
     ]
    }
   ],
   "source": [
    "result_final=model_final.evaluate(X_test,y_test)\n",
    "print(\"Test Accuracy on Testing data:\",result_final[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Digits using NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18ad7500d08>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[112].reshape(32,32),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.predict_classes(X_test)[112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18ad8ff8308>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[55].reshape(32,32),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.predict_classes(X_test)[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18ad910d808>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[265].reshape(32,32),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.predict_classes(X_test)[265]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18ad5acde48>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[272].reshape(32,32),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.predict_classes(X_test)[272]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18ad2911f08>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[745].reshape(32,32),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.predict_classes(X_test)[745]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18ad7621e08>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[121].reshape(32,32),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.predict_classes(X_test)[121]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NN with batchNormalization we got 82% accuracy. We have predicted the classification of the images correctly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
